# Handoff Document: Semantic Search Vector Query Troubleshooting

**Date:** 2025-06-19
**Project:** ScraperSky Backend - Vector Database Semantic Search
**Handoff From:** Cascade AI (Session ending)
**Handoff To:** Next Cascade AI Agent

## 1. Overall Objective

The primary goal is to successfully perform an end-to-end semantic search using a query embedding generated by a Python script (`generate_query_embedding.py`) against the Supabase vector database (`project_docs` table, `embedding` column of type `halfvec(1536)`).
The query string for testing is "JavaScript Files & Variables".
The project ID for database operations is `ddfldwzhdhhzhxywqnyz`.

## 2. Critical Issue Encountered

A persistent error: `ERROR: 22000: expected 1536 dimensions, not 287` occurs when attempting to use the 1536-dimension query vector (generated by OpenAI's `text-embedding-ada-002` model) in SQL queries executed via the `mcp4_execute_sql` tool.
This error suggests that the string representation of the vector, when passed to PostgreSQL, is being misinterpreted or truncated in a way that results in it being seen as a 287-dimension vector. The number 287 is consistently reported in the error messages.

## 3. Attempts Made & Current State

### A. Python Script for Embedding Generation:
*   The script `Docs/Docs_18_Vector_Operations/Scripts/generate_query_embedding.py` was developed and successfully generates a 1536-dimension vector string for a given query.
*   Example output for "JavaScript Files & Variables": `[-0.01900411583483219,0.004156720824539661,...,-0.04633541405200958]` (the full vector is very long).

### B. Direct SQL Query with Vector Literal (via `mcp4_execute_sql`):
*   **Attempt 1:** Using `::vector` cast.
    *   Query: `SELECT id, title, 1 - (embedding <=> '[-0.019...]'::vector) as similarity FROM public.project_docs ORDER BY similarity DESC LIMIT 5;`
    *   Result: `ERROR: 22000: different halfvec dimensions 1536 and 287`
*   **Attempt 2:** Using `::halfvec(1536)` cast.
    *   Query: `SELECT id, title, 1 - (embedding <=> '[-0.019...]'::halfvec(1536)) as similarity FROM public.project_docs ORDER BY similarity DESC LIMIT 5;`
    *   Result: `ERROR: 22000: expected 1536 dimensions, not 287`

### C. PL/pgSQL Stored Function (via `mcp4_execute_sql`):
*   A function `perform_semantic_search(query_vector_text TEXT)` was created in the database to handle the string-to-vector conversion internally:
    ```sql
    CREATE OR REPLACE FUNCTION perform_semantic_search(query_vector_text TEXT)
    RETURNS TABLE(id UUID, title TEXT, similarity REAL) AS $$
    DECLARE
        query_embedding halfvec(1536);
        cleaned_vector_string TEXT;
    BEGIN
        -- Remove brackets and split into an array of text, then cast to real[], then to halfvec(1536)
        cleaned_vector_string := trim(BOTH '[]' FROM query_vector_text);
        query_embedding := string_to_array(cleaned_vector_string, ',')::real[]::halfvec(1536);

        RETURN QUERY
        SELECT pd.id, pd.title, (1 - (pd.embedding <=> query_embedding)) AS similarity
        FROM public.project_docs pd
        ORDER BY similarity DESC
        LIMIT 5;
    EXCEPTION
        WHEN OTHERS THEN
            RAISE WARNING 'Error in perform_semantic_search: SQLSTATE: %, SQLERRM: %', SQLSTATE, SQLERRM;
            RAISE INFO 'Input query_vector_text was: %', query_vector_text;
            RAISE INFO 'Cleaned vector string was: %', cleaned_vector_string;
            RETURN; -- Returns an empty set on error after logging
    END;
    $$ LANGUAGE plpgsql;
    ```
*   **Call Attempt:** `SELECT id, title, similarity FROM perform_semantic_search('[-0.019...]')`
    *   Result from `mcp4_execute_sql`: Empty `[]`
    *   PostgreSQL Logs (retrieved via `mcp4_get_logs` for service `postgres`):
        `WARNING: Error in perform_semantic_search: SQLSTATE: 22000, SQLERRM: expected 1536 dimensions, not 287`
*   This confirms the dimension misinterpretation issue persists even when the conversion logic is within a PL/pgSQL function, if the long vector string is passed as a text argument.

## 4. Key Observations & Hypotheses

*   The OpenAI `text-embedding-ada-002` model correctly produces 1536-dimension vectors.
*   The target database column `project_docs.embedding` is correctly typed as `halfvec(1536)`.
*   The error is consistently about the input vector string being interpreted as having 287 dimensions, not a type mismatch (e.g., `vector` vs `halfvec`).
*   The extreme length of the 1536-dimension floating-point vector string might be exceeding a processing limit or causing a parsing anomaly within the `mcp4_execute_sql` tool's pathway, or the underlying Supabase/PostgreSQL interface when passed as a single large string literal or text argument.

## 5. Suggested Next Steps for Investigation

*   **A. Parameterized Queries / Alternative Data Passing:**
    *   The most crucial area to investigate is whether `mcp4_execute_sql` (or the Supabase client libraries it might be using) supports a way to pass the vector data as a structured type (e.g., an array of floats) rather than a single, extremely long string that SQL then needs to parse. This is how client libraries (like `supabase-js`) typically handle such data, often avoiding manual string literal construction. If `mcp4_execute_sql` is a thin wrapper, it might not expose this.
*   **B. Test with Shorter Vectors:**
    *   Create a temporary table, e.g., `CREATE TABLE temp_test_vectors (id SERIAL PRIMARY KEY, embedding_val halfvec(3));`.
    *   Insert a known 3-dimension vector: `INSERT INTO temp_test_vectors (embedding_val) VALUES ('[0.1,0.2,0.3]');`.
    *   Attempt to query it using `mcp4_execute_sql` with a 3-dimension vector string literal: `SELECT id FROM temp_test_vectors WHERE embedding_val <=> '[0.1,0.2,0.3]'::halfvec(3) < 0.1;`.
    *   If this works, it strongly points towards an issue related to the length of the 1536-dimension string.
*   **C. Investigate the "287" Dimension Anomaly:**
    *   The number 287 is unusual. It's not a power of 2, nor does it immediately relate to common buffer sizes (e.g., 1024, 4096 characters) in a simple way. Further thought on what could lead to this specific number during string processing or array conversion might be useful. (e.g., `1536 floats * approx 10-15 chars/float with commas = 15-20KB string`. Is there a limit around 4KB or 8KB for string literals or arguments in some intermediate step that causes an odd truncation?)
*   **D. Supabase Documentation & Support:**
    *   Deep dive into Supabase documentation regarding limits on string literal sizes in SQL queries, argument length limits for PL/pgSQL functions when called via their API/tools, or best practices for handling large vector data with `mcp4_execute_sql`.
    *   If the tool's limitations are the blocker, this might require escalating to understand the tool's capabilities better.
*   **E. Refine PL/pgSQL Parsing (If Full String Reaches Function):**
    *   If it's confirmed the *entire* vector string *does* reach the PL/pgSQL function intact, explore alternative string parsing mechanisms within PL/pgSQL. For example, using `regexp_split_to_array` or iterating through elements if the current `string_to_array` combined with casting is problematic for very long inputs. However, the logs suggest the error occurs *during* the `string_to_array(...)::real[]::halfvec(1536)` step.

## 6. Relevant Artifacts

*   **Python Embedding Script:** `/Users/henrygroman/development/python-projects/ScraperSky-Back-End-WorkSpace/scraper-sky-backend/Docs/Docs_18_Vector_Operations/Scripts/generate_query_embedding.py`
*   **SQL Function:** `perform_semantic_search(query_vector_text TEXT)` (created in project `ddfldwzhdhhzhxywqnyz`).
*   **Target Table:** `public.project_docs` (column: `embedding halfvec(1536)`).
*   **Project ID:** `ddfldwzhdhhzhxywqnyz`
