# Correct Vector DB Setup Guide

**Last Updated:** 2025-06-10

> **ARCHITECTURAL NOTE:** This document replaces the obsolete `v_supabase_setup.md`, which has been archived. The previous guide detailed a flawed, non-functional server-side embedding workflow. This guide documents the **correct, verified, client-side workflow** that is currently in use.

## Core Principle: Client-Side Embeddings

The ScraperSky vector database operates on a **client-side embedding model**. All vector embeddings are generated by Python scripts using the OpenAI API *before* being inserted into the database. The database's role is to store these vectors and perform similarity searches. **There is no server-side embedding generation.**

## The Three Pillars of the Vector DB System

The system is composed of three interconnected components:

1.  **The Document Registry (`document_registry` table):** The single source of truth for all documents eligible for vectorization. It tracks file paths, status (`active`, `archived`, `needs_update`), and metadata.
2.  **The Registry Management Scripts (`Docs/Docs_19_File-2-Vector-Registry-System/`):** A suite of Python tools to manage the registry. This includes scanning for new documents, archiving old ones, and flagging documents for updates.
3.  **The Vector Database (`project_docs` table):** The final storage for vectorized content. It holds the document title, content, and the pre-generated embedding.

---

## Step-by-Step Setup and Workflow

### Step 1: Database Schema

The following schema is the correct and minimal setup required.

**`project_docs` Table:**
This table stores the final vectorized content.

```sql
-- Create the table for storing vectorized documents
CREATE TABLE IF NOT EXISTS public.project_docs (
  id SERIAL PRIMARY KEY,
  title TEXT,
  content TEXT,
  embedding VECTOR(1536),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

**`document_registry` Table:**
This table is managed by the registry scripts and should not be manually altered unless for specific maintenance.

### Step 2: Enabling the `vector` Extension

Ensure the `vector` extension is enabled in your Supabase project. This is typically done once via the Supabase Dashboard under `Database > Extensions`.

```sql
-- Enable vector extension if not already enabled
CREATE EXTENSION IF NOT EXISTS vector;
```

### Step 3: The Document Ingestion Workflow

This is the standard process for adding or updating a document in the vector database.

1.  **Add the Document:** Place the new markdown file in one of the approved directories (e.g., `Docs/Docs_6_Architecture_and_Status/`).
2.  **Scan the Registry:** Run the document scanner to discover the new file and add it to the `document_registry`.
    ```bash
    python3 Docs/Docs_19_File-2-Vector-Registry-System/2-registry-document-scanner.py --scan
    ```
3.  **Flag for Update:** Mark the document for processing.
    ```bash
    # Example for a new document
    python3 Docs/Docs_19_File-2-Vector-Registry-System/3-registry-update-flag-manager.py --mark-for-update 'path/to/your/document.md'
    ```
4.  **Run the Ingestion Script:** This script finds all documents marked `needs_update`, generates embeddings, and inserts them into the `project_docs` table.
    ```bash
    python3 Docs/Docs_18_Vector_Operations/Scripts/insert_architectural_docs.py
    ```

### Step 4: Performing a Vector Search

All vector searches must be performed from a client-side script that generates an embedding for the query text first. The `Docs/Docs_18_Vector_Operations/Scripts/simple_test.py` script provides the canonical example.

**Example Search Logic (from `simple_test.py`):**

```python
import os
import asyncio
from openai import AsyncOpenAI
import asyncpg
from dotenv import load_dotenv

# 1. Get OpenAI client
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 2. Define your search query
search_query = "What are the architectural anti-patterns?"

# 3. Generate embedding for the query
response = await client.embeddings.create(
    input=search_query,
    model="text-embedding-ada-002"
)
query_embedding = response.data[0].embedding

# 4. Connect to the database and execute the search
conn = await asyncpg.connect(os.getenv("DATABASE_URL"))
results = await conn.fetch(
    """
    SELECT
        title,
        content,
        1 - (embedding <=> $1) as similarity
    FROM project_docs
    ORDER BY embedding <=> $1
    LIMIT 5;
    """,
    query_embedding
)

# 5. Process results
for r in results:
    print(f"Document: {r['title']} - Similarity: {r['similarity']:.4f}")

await conn.close()
```

This workflow is robust, verifiable, and correctly aligned with the platform's capabilities.
