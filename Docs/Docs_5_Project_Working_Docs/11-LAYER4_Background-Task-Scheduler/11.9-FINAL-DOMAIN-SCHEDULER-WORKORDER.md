# Final Domain Scheduler Work Order

## Executive Summary

A comprehensive review of all documentation in the `./project-docs/11-Background-Task-Scheduler` folder was conducted. The critical database conformance issues have been addressed in the implemented fixes (11.7), but several important improvements remain to fully modernize the scheduler system.

## Project Status

| Component                       | Status        | Documentation                                                                               | Completion Date |
| ------------------------------- | ------------- | ------------------------------------------------------------------------------------------- | --------------- |
| Database Conformance Fixes      | **COMPLETED** | `/project-docs/11-Background-Task-Scheduler/11.7-DOMAIN-SCHEDULER-BUGFIX-IMPLEMENTATION.md` | Mar 31, 2025    |
| URL Formatting Fix              | **COMPLETED** | `/project-docs/11-Background-Task-Scheduler/11.4-domain_scheduler_changes_report.md`        | Mar 31, 2025    |
| Standalone Test Scripts         | **COMPLETED** | `/project-docs/11-Background-Task-Scheduler/11.5-domain_scheduler_test_scripts.md`          | Mar 31, 2025    |
| FastAPI Lifespan Migration      | **PENDING**   | `/project-docs/11-Background-Task-Scheduler/11.8-FUTURE-DOMAIN-SCHEDULER-IMPROVEMENTS.md`   | -               |
| Configurable Scheduler Settings | **PENDING**   | `/project-docs/11-Background-Task-Scheduler/11.8-FUTURE-DOMAIN-SCHEDULER-IMPROVEMENTS.md`   | -               |
| Enhanced Telemetry              | **PENDING**   | `/project-docs/11-Background-Task-Scheduler/11.8-FUTURE-DOMAIN-SCHEDULER-IMPROVEMENTS.md`   | -               |
| Status Value Consistency Check  | **PENDING**   | `/project-docs/11-Background-Task-Scheduler/11.2-Work-Order-Scheduler-Debug.md`             | -               |

## Key Files and Locations

- **Domain Scheduler**: `/src/services/domain_scheduler.py`
- **FastAPI Application**: `/src/main.py`
- **Application Settings**: `/src/config/settings.py`
- **Metadata Extractor**: `/src/scraper/metadata_extractor.py`
- **API Endpoints**: `/src/routers/modernized_page_scraper.py`
- **Database Session**: `/src/session/async_session.py`
- **Domain Utilities**: `/src/scraper/domain_utils.py`

## Work Items Prioritized

### 1. FastAPI Lifespan Migration (HIGH PRIORITY)

**Issue:** The application uses deprecated `@app.on_event()` handlers for scheduler startup/shutdown instead of the modern lifespan pattern.

**Current Implementation:**

```python
# Current implementation in /src/main.py

@app.on_event("startup")
async def startup_event():
    """Initialize resources on application startup."""
    logger.info("Starting up the ScraperSky API")

    # Start the domain processing scheduler
    setup_domain_scheduler()
    logger.info("Domain processing scheduler started")

@app.on_event("shutdown")
async def shutdown_event():
    """Clean up resources on application shutdown."""
    # Shutdown the metadata extractor session
    await session_manager.close()

    # Shutdown the domain scheduler
    shutdown_domain_scheduler()
    logger.info("Domain processing scheduler shut down")
```

**Required Changes:**

- Modify `/src/main.py` to use the lifespan context manager pattern
- Ensure all current startup/shutdown operations are preserved
- Keep the same imports and function calls for consistency

**Implementation Instructions:**

```python
# New implementation for /src/main.py

from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Lifespan context manager for FastAPI application.
    This replaces the deprecated @app.on_event handlers.
    """
    # Startup logic
    logger.info("Starting up the ScraperSky API")

    # Start the domain processing scheduler
    scheduler = setup_domain_scheduler()
    logger.info("Domain processing scheduler started")

    yield  # This is where FastAPI runs and serves requests

    # Shutdown logic
    await session_manager.close()
    shutdown_domain_scheduler()
    logger.info("Domain processing scheduler shut down")

# Create FastAPI app with lifespan manager
app = FastAPI(
    title="ScraperSky API",
    description="API for ScraperSky web scraping and data management",
    version="3.0.0",
    debug=True,
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
    lifespan=lifespan  # Use the lifespan context manager
)
```

**Acceptance Criteria:**

- Application startup uses the new lifespan pattern
- Domain scheduler initializes correctly with the new pattern
- Clean shutdown is achieved with all resources properly released
- No deprecation warnings in logs related to event handlers

**Testing Steps:**

1. Start the application with Docker Compose: `docker-compose up`
2. Check logs for successful scheduler initialization: `docker-compose logs | grep scheduler`
3. Submit a test domain and verify processing:
   ```bash
   curl -X POST "http://localhost:8000/api/v3/modernized_page_scraper/scan" \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer scraper_sky_2024" \
     -d '{"base_url":"example.com", "max_pages":5}'
   ```
4. Gracefully stop the application and check logs for proper shutdown

**Estimated Effort:** 1 day

### 2. Status Value Consistency Check (HIGH PRIORITY)

**Issue:** Potential mismatch between the domain status values set by the API endpoint and what the scheduler expects.

**Verification Steps:**

1. Check what status value the scheduler is looking for:

   ```bash
   docker-compose exec scrapersky grep -n "status" /src/services/domain_scheduler.py
   ```

   Current query in the scheduler (around line 95-100):

   ```python
   # Look for code like this in /src/services/domain_scheduler.py
   query = text("""
   SELECT * FROM domains
   WHERE status = 'pending'
   ORDER BY updated_at ASC
   LIMIT :limit
   """)
   ```

2. Check what status the API sets:
   ```bash
   docker-compose exec scrapersky grep -n "status" /src/routers/modernized_page_scraper.py
   ```
   Look for where domains are created or updated in the API.

**Required Changes:**

- If a mismatch is found, modify either:
  - The API endpoint to set the status that the scheduler expects (likely 'pending')
  - The scheduler to look for the status that the API sets
- If needed, add support for multiple status values in the scheduler query

**Implementation Example:**
If the API sets a different status than 'pending', update the scheduler query:

```python
# In /src/services/domain_scheduler.py
query = text("""
SELECT * FROM domains
WHERE status IN ('pending', 'queued', 'submitted')  # Add all valid statuses
ORDER BY updated_at ASC
LIMIT :limit
""")
```

**Test and Fix Procedure:**

1. Submit a test domain via API endpoint:

   ```bash
   curl -X POST "http://localhost:8000/api/v3/modernized_page_scraper/scan" \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer scraper_sky_2024" \
     -d '{"base_url":"test-status-check.com", "max_pages":5}'
   ```

2. Check the domain's status in the database:

   ```bash
   docker-compose exec scrapersky python scripts/db/simple_inspect.py "SELECT id, domain, status FROM domains WHERE domain = 'test-status-check.com'"
   ```

3. If the status doesn't match what the scheduler expects:

   - Update domains to the expected status for testing:

   ```bash
   docker-compose exec scrapersky python -c "
   import asyncio
   from sqlalchemy import text
   from src.session.async_session import get_background_session

   async def update_statuses():
       async with get_background_session() as session:
           async with session.begin():
               query = text(\"\"\"
               UPDATE domains
               SET status = 'pending'
               WHERE status = 'actual_status'
               RETURNING id, domain, status
               \"\"\")
               result = await session.execute(query)
               rows = result.fetchall()
               print(f'Updated {len(rows)} domains to pending status')

   asyncio.run(update_statuses())
   "
   ```

**Acceptance Criteria:**

- Status values are consistent between API and scheduler
- Domains submitted via the Single Domain Scanner are successfully picked up by the scheduler
- Clear documentation of the domain lifecycle states

**Estimated Effort:** 1 day

### 3. Complete Database Insertion Test (MEDIUM PRIORITY)

**Issue:** The database insertion test script from `/project-docs/11-Background-Task-Scheduler/11.3-DATABASE-INSERT-TEST-WORKORDER.md` needs to be completed and verified.

**File Location:** Create `/scripts/test_db_insert.py`

**Implementation Template:**

```python
"""
Database Insertion Test Script

This script tests the database insertion part of domain processing,
following all architectural standards for background tasks.
"""

import asyncio
import logging
import sys
import json
from pathlib import Path
from typing import Dict, Any, Optional
from uuid import UUID

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

# Correct import path
from src.session.async_session import get_background_session

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('db-insertion-test')

# Mock data generation
def create_mock_metadata() -> Dict[str, Any]:
    """Create realistic-looking mock metadata for testing"""
    return {
        "title": "Test Company | Digital Solutions",
        "description": "Leading provider of digital transformation solutions for enterprise businesses.",
        "is_wordpress": True,
        "url": "https://testcompany.com",
        "phone_numbers": ["(555) 123-4567", "1-800-555-9876"],
        "email_addresses": ["contact@testcompany.com", "support@testcompany.com"],
        "social_media": {
            "twitter": "https://twitter.com/testcompany",
            "linkedin": "https://linkedin.com/company/testcompany"
        },
        "meta_tags": {
            "keywords": "digital solutions, enterprise software, cloud services"
        }
    }

# Database insertion - follows architectural principles
async def update_domain_with_metadata(domain_id: str, metadata: Dict[str, Any]) -> bool:
    """
    Update a domain record with extracted metadata.

    Args:
        domain_id: UUID of the domain to update
        metadata: Dictionary containing extracted metadata

    Returns:
        True if update was successful, False otherwise
    """
    try:
        # Get background session following architectural standards
        async with get_background_session() as session:
            # Set Supavisor options
            try:
                logger.debug("Setting session options for Supavisor compatibility")

                # Required Supavisor parameters
                options = [
                    ("SET statement_timeout = 90000", "90 seconds timeout"),
                    ("SET idle_in_transaction_session_timeout = 120000", "120 seconds idle timeout"),
                    ("SET statement_cache_size = 0", "Required for Supavisor compatibility")
                ]

                for sql, description in options:
                    set_option = text(sql)
                    set_option = set_option.execution_options(prepared=False)
                    await session.execute(set_option)
                    logger.debug(f"Set session option: {description}")
            except Exception as e:
                logger.error(f"Error setting session options: {str(e)}")
                return False

            # Begin transaction (background tasks manage their own transactions)
            async with session.begin():
                # Prepare SQL query with execution options for Supavisor
                query = text("""
                UPDATE domains
                SET status = 'test-processed',
                    title = :title,
                    description = :description,
                    is_wordpress = :is_wordpress,
                    phone_numbers = :phone_numbers,
                    email_addresses = :email_addresses,
                    domain_metadata = :metadata,
                    updated_at = NOW()
                WHERE id = :id
                RETURNING id, domain, status
                """)

                # Set execution options for Supavisor compatibility
                query = query.execution_options(prepared=False)

                # Execute query with parameters
                result = await session.execute(query, {
                    'id': domain_id,
                    'title': metadata.get('title', ''),
                    'description': metadata.get('description', ''),
                    'is_wordpress': metadata.get('is_wordpress', False),
                    'phone_numbers': metadata.get('phone_numbers', []),
                    'email_addresses': metadata.get('email_addresses', []),
                    'metadata': metadata
                })

                # Get the returned row (will be None if domain_id doesn't exist)
                returned_row = result.fetchone()

                if returned_row:
                    logger.info(f"Successfully updated domain {returned_row.domain} with status {returned_row.status}")
                    return True
                else:
                    logger.warning(f"No domain found with ID {domain_id}")
                    return False

    except Exception as e:
        logger.error(f"Error updating domain {domain_id}: {str(e)}")

        # Handle error recording in separate session/transaction
        try:
            async with get_background_session() as error_session:
                # Set Supavisor options for error session
                try:
                    for sql, description in options:
                        set_option = text(sql)
                        set_option = set_option.execution_options(prepared=False)
                        await error_session.execute(set_option)
                except Exception:
                    pass

                async with error_session.begin():
                    error_query = text("""
                    UPDATE domains
                    SET status = 'test-error',
                        last_error = :error_msg,
                        updated_at = NOW()
                    WHERE id = :id
                    """)

                    error_query = error_query.execution_options(prepared=False)

                    await error_session.execute(error_query, {
                        'id': domain_id,
                        'error_msg': str(e)
                    })
        except Exception as error_update_error:
            logger.error(f"Failed to record error state: {str(error_update_error)}")
        return False

# Main test function
async def run_test(domain_id: Optional[str] = None):
    """
    Run the database insertion test.

    Args:
        domain_id: Optional domain ID to test with. If not provided,
                  will create a new test domain.
    """
    # Create test domain if none provided
    if not domain_id:
        domain_id = await create_test_domain()
        if not domain_id:
            logger.error("Failed to create test domain. Aborting test.")
            return

    # Generate mock metadata
    metadata = create_mock_metadata()
    logger.info(f"Generated mock metadata for testing: {json.dumps(metadata, indent=2)}")

    # Update domain with metadata
    logger.info(f"Updating domain {domain_id} with mock metadata...")
    result = await update_domain_with_metadata(domain_id, metadata)

    # Check result
    if result:
        logger.info("✅ TEST PASSED: Successfully updated domain with metadata")
    else:
        logger.error("❌ TEST FAILED: Failed to update domain with metadata")

    # Verify the update in database
    await verify_domain_update(domain_id)

# Helper to create a test domain
async def create_test_domain() -> Optional[str]:
    """Create a test domain and return its ID"""
    try:
        async with get_background_session() as session:
            async with session.begin():
                query = text("""
                INSERT INTO domains (id, tenant_id, domain, status, created_at, updated_at)
                VALUES (:id, '550e8400-e29b-41d4-a716-446655440000', :domain, 'test-pending', NOW(), NOW())
                RETURNING id
                """)

                query = query.execution_options(prepared=False)

                import uuid
                domain_id = str(uuid.uuid4())
                result = await session.execute(query, {
                    'id': domain_id,
                    'domain': f'test-domain-{domain_id[:8]}.com'
                })

                returned_id = result.scalar_one()
                logger.info(f"Created test domain with ID: {returned_id}")
                return returned_id
    except Exception as e:
        logger.error(f"Error creating test domain: {str(e)}")
        return None

# Helper to verify the domain was updated
async def verify_domain_update(domain_id: str):
    """Verify the domain update by querying the database"""
    try:
        async with get_background_session() as session:
            query = text("""
            SELECT id, domain, status, title, description, is_wordpress, updated_at
            FROM domains
            WHERE id = :id
            """)

            query = query.execution_options(prepared=False)
            result = await session.execute(query, {'id': domain_id})
            domain = result.mappings().one_or_none()

            if domain:
                logger.info("Domain state after update:")
                for key, value in dict(domain).items():
                    logger.info(f"  {key}: {value}")
            else:
                logger.error(f"Domain {domain_id} not found in database")
    except Exception as e:
        logger.error(f"Error verifying domain update: {str(e)}")

# Command-line entry point
if __name__ == "__main__":
    domain_id = sys.argv[1] if len(sys.argv) > 1 else None
    asyncio.run(run_test(domain_id))
```

**Test Execution:**

```bash
# Execute test with a new domain
docker-compose exec scrapersky python scripts/test_db_insert.py

# Or test with existing domain ID
docker-compose exec scrapersky python scripts/test_db_insert.py "existing-domain-uuid"
```

**Acceptance Criteria:**

- Working test script available in `scripts/test_db_insert.py`
- Successful test execution with proper logging
- Documentation of insertion patterns and transaction handling
- Proper error handling and reporting

**Estimated Effort:** 1 day

### 4. Configurable Scheduler Parameters (MEDIUM PRIORITY)

**Issue:** Scheduler parameters like interval and batch size are hardcoded in the `domain_scheduler.py` file.

**Current Implementation:**

```python
# In /src/services/domain_scheduler.py
job = scheduler.add_job(
    process_pending_domains,
    IntervalTrigger(minutes=1),
    id="process_pending_domains",
    replace_existing=True,
    kwargs={"limit": 10}  # Process up to 10 domains each time
)
```

**Required Changes:**

1. Add configuration options to `/src/config/settings.py`:

```python
# Add to Settings class in /src/config/settings.py
# Scheduler settings
SCHEDULER_INTERVAL_MINUTES: int = 1
SCHEDULER_BATCH_SIZE: int = 10
SCHEDULER_MAX_INSTANCES: int = 1
```

2. Update domain scheduler to use settings:

```python
# In /src/services/domain_scheduler.py

# Import settings
from ..config.settings import settings

def setup_domain_scheduler():
    """Set up the scheduler with the domain processing job"""
    logger.info("Setting up domain processing scheduler")

    # Use settings for scheduler configuration
    job = scheduler.add_job(
        process_pending_domains,
        IntervalTrigger(minutes=settings.SCHEDULER_INTERVAL_MINUTES),
        id="process_pending_domains",
        replace_existing=True,
        kwargs={"limit": settings.SCHEDULER_BATCH_SIZE}
    )

    # ... rest of the function ...
```

3. Add documentation in code comments.

**Testing Steps:**

1. Set different values in environment or settings
2. Restart the application
3. Verify scheduler uses the new values (check logs)

**Acceptance Criteria:**

- All scheduler parameters configurable via settings
- Default values provide backward compatibility
- Configuration documentation in README.md or inline comments

**Estimated Effort:** 0.5 days

### 5. Enhanced Telemetry and Monitoring (LOW PRIORITY)

**Issue:** Basic logging without structured metrics for scheduler performance.

**Current Implementation:**

```python
# In /src/services/domain_scheduler.py
# Log completion statistics
logger.debug("--------------------------------------------------")
logger.debug(f"DOMAIN PROCESSING JOB {job_id} COMPLETE")
logger.debug(f"Processed: {domains_processed} domains, Successful: {domains_successful}")
logger.debug("--------------------------------------------------")
```

**Required Changes:**

1. Add `SchedulerMetrics` class as specified in `/project-docs/11-Background-Task-Scheduler/11.8-FUTURE-DOMAIN-SCHEDULER-IMPROVEMENTS.md`
2. Update `process_pending_domains` to use this class
3. Create a metrics storage function

**Implementation Example:**

```python
# In /src/services/domain_scheduler.py
import time
from dataclasses import dataclass
from typing import Dict, Any

@dataclass
class SchedulerMetrics:
    job_id: str
    start_time: float
    end_time: float
    domains_processed: int
    domains_successful: int
    domains_failed: int
    domains_skipped: int

    @property
    def duration_seconds(self) -> float:
        return self.end_time - self.start_time

    @property
    def success_rate(self) -> float:
        return self.domains_successful / self.domains_processed if self.domains_processed > 0 else 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "job_id": self.job_id,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(self.end_time)),
            "duration_seconds": self.duration_seconds,
            "domains_processed": self.domains_processed,
            "domains_successful": self.domains_successful,
            "domains_failed": self.domains_failed,
            "domains_skipped": self.domains_skipped,
            "success_rate": self.success_rate
        }

async def store_scheduler_metrics(metrics: SchedulerMetrics):
    """Store scheduler metrics for monitoring purposes."""
    # You can implement different storage options:
    # 1. Log to file
    logger.info(f"SCHEDULER_METRICS: {json.dumps(metrics.to_dict())}")

    # 2. Store in database (optional)
    try:
        async with get_background_session() as session:
            async with session.begin():
                # Set Supavisor options
                for sql, description in [
                    ("SET statement_timeout = 90000", "90 seconds timeout"),
                    ("SET idle_in_transaction_session_timeout = 120000", "120 seconds idle timeout"),
                    ("SET statement_cache_size = 0", "Required for Supavisor compatibility")
                ]:
                    await session.execute(text(sql).execution_options(prepared=False))

                # Insert metrics
                query = text("""
                INSERT INTO scheduler_metrics
                (job_id, timestamp, duration_seconds, domains_processed,
                 domains_successful, domains_failed, domains_skipped, success_rate)
                VALUES
                (:job_id, NOW(), :duration_seconds, :domains_processed,
                 :domains_successful, :domains_failed, :domains_skipped, :success_rate)
                """)

                await session.execute(query.execution_options(prepared=False), {
                    "job_id": metrics.job_id,
                    "duration_seconds": metrics.duration_seconds,
                    "domains_processed": metrics.domains_processed,
                    "domains_successful": metrics.domains_successful,
                    "domains_failed": metrics.domains_failed,
                    "domains_skipped": metrics.domains_skipped,
                    "success_rate": metrics.success_rate
                })
    except Exception as e:
        logger.error(f"Failed to store metrics in database: {str(e)}")

async def process_pending_domains(limit: int = 10):
    """Process pending domains with enhanced telemetry."""
    start_time = time.time()
    job_id = f"domain_batch_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"

    # Initialize metrics
    metrics = SchedulerMetrics(
        job_id=job_id,
        start_time=start_time,
        end_time=0,
        domains_processed=0,
        domains_successful=0,
        domains_failed=0,
        domains_skipped=0
    )

    # ... existing processing code with metrics collection ...

    # Update metrics at the end
    metrics.end_time = time.time()
    metrics.domains_processed = domains_processed
    metrics.domains_successful = domains_successful
    metrics.domains_failed = domains_processed - domains_successful

    # Store metrics
    await store_scheduler_metrics(metrics)

    # Log completion statistics
    logger.debug("--------------------------------------------------")
    logger.debug(f"DOMAIN PROCESSING JOB {job_id} COMPLETE")
    logger.debug(f"Processed: {domains_processed} domains, Successful: {domains_successful}")
    logger.debug(f"Duration: {metrics.duration_seconds:.2f} seconds, Success rate: {metrics.success_rate:.2%}")
    logger.debug("--------------------------------------------------")
```

**Acceptance Criteria:**

- Structured metrics for each scheduler run
- Performance data including duration, success rates, etc.
- Easily parseable log format for monitoring systems

**Estimated Effort:** 2-3 days

## Testing Requirements

### 1. End-to-End Flow Testing

Test the entire flow from domain submission to processing:

```bash
# Run from a terminal
curl -X POST "http://localhost:8000/api/v3/modernized_page_scraper/scan" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer scraper_sky_2024" \
  -d '{"base_url":"example.com", "max_pages":5}'
```

You'll receive a response with a job ID:

```json
{
  "job_id": "e9895e9a-5337-4830-b295-83e14c028f8c",
  "status_url": "/api/v3/modernized_page_scraper/status/e9895e9a-5337-4830-b295-83e14c028f8c",
  "created_at": "2025-03-31T13:00:35.649776"
}
```

Check the status:

```bash
curl "http://localhost:8000/api/v3/modernized_page_scraper/status/e9895e9a-5337-4830-b295-83e14c028f8c"
```

Verify domain in database:

```bash
docker-compose exec scrapersky python scripts/db/simple_inspect.py "SELECT id, domain, status FROM domains WHERE domain = 'example.com'"
```

### 2. Database Access Instructions

To debug the domain scheduler, inspect the domains table:

```bash
# View domains table schema and data
docker-compose exec scrapersky python scripts/db/simple_inspect.py domains --limit 20
```

Key fields to examine:

- `status`: Overall domain status ('active', 'processing', 'completed', etc.)
- `content_scrape_status`: More specific status for content scraping
- `page_scrape_status`: Status for page scraping
- `sitemap_monitor_status`: Status for sitemap monitoring

Check scheduler status in logs:

```bash
# View the most recent logs looking for scheduler activity
docker-compose exec scrapersky tail -n 100 logs/app.log | grep -i scheduler
```

## Implementation Plan

### Phase 1: Critical Improvements (1-2 weeks)

1. FastAPI Lifespan Migration
2. Status Value Consistency Check
3. Complete Database Insertion Test

### Phase 2: Functional Enhancements (1-2 weeks)

1. Configurable Scheduler Parameters
2. Enhanced Telemetry and Monitoring

## Development Environment Setup

The application runs in Docker containers. Use these commands for development:

```bash
# Start the application
docker-compose up -d

# View logs
docker-compose logs -f

# Execute commands in the container
docker-compose exec scrapersky <command>

# Stop the application
docker-compose down
```

## Technical Notes

This work order consolidates information from multiple documents, with particular attention to:

1. Initial debugging work order (`/project-docs/11-Background-Task-Scheduler/11.2-Work-Order-Scheduler-Debug.md`)
2. Database insertion testing (`/project-docs/11-Background-Task-Scheduler/11.3-DATABASE-INSERT-TEST-WORKORDER.md`)
3. Completed changes report (`/project-docs/11-Background-Task-Scheduler/11.4-domain_scheduler_changes_report.md`)
4. Test script documentation (`/project-docs/11-Background-Task-Scheduler/11.5-domain_scheduler_test_scripts.md`)
5. Database conformance work order (`/project-docs/11-Background-Task-Scheduler/11.6-DOMAIN-SCHEDULER-CONFORMANCE-WORKORDER.md`)
6. Implementation of fixes (`/project-docs/11-Background-Task-Scheduler/11.7-DOMAIN-SCHEDULER-BUGFIX-IMPLEMENTATION.md`)
7. Future improvements documentation (`/project-docs/11-Background-Task-Scheduler/11.8-FUTURE-DOMAIN-SCHEDULER-IMPROVEMENTS.md`)

The completed database conformance fixes have addressed the most critical issues, but the remaining tasks are necessary to fully modernize the scheduler component and ensure robust operation in production.

## References

- `/src/services/domain_scheduler.py` - Main scheduler implementation
- `/src/main.py` - FastAPI application setup
- `/src/config/settings.py` - Application configuration
- `/Docs/Docs_1_AI_GUIDES/07-DATABASE_CONNECTION_STANDARDS.md` - Database standards
- `/Docs/Docs_1_AI_GUIDES/21-SCHEDULED_TASKS_APSCHEDULER_PATTERN.md` - Scheduler patterns
