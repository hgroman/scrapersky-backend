| Phase                            | What to do                                                                                                                                                                                                                              | Why it matters (bottlenecks avoided)                                                                                                                                            |                                                                                  |
| -------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- |
| **1. Discover URLs**             | • Let **crawl4ai** drive the crawl, but first: <br>   ◦ Read `sitemap.xml` if it exists (fewer misses) <br>   ◦ Normalize each URL (strip `utm_*`, lowercase host, etc.) <br>   ◦ Skip if its SHA‑256 **content hash** is already in DB | Stops duplicate fetches and keeps crawl scope tight.                                                                                                                            |                                                                                  |
| **2. Fetch politely**            | • Enable robots.txt checks <br>• Per‑domain rate‑limiter with jitter + exponential back‑off on 429/503 <br>• Cap Playwright pages to \~5‑8 on a 2 GB box; crawler auto‑throttles if RAM is low                                          | Prevents site bans **and** memory blow‑ups on small Render instances.                                                                                                           |                                                                                  |
| **3. Parse & store raw page**    | • Strip HTML → text <br>• Gzip raw HTML to Supabase Storage; save its hash                                                                                                                                                              | Gives you a replayable snapshot and a fast dedup key without bloating Postgres.                                                                                                 |                                                                                  |
| **4. Chunk & embed**             | • Split text by \~800 tokens with 200‑token overlap <br>• Insert chunks (not whole pages) into `page_content_vectors`                                                                                                                   | Improves semantic search quality and keeps each vector within model limits.                                                                                                     |                                                                                  |
| **5. Generate vectors (async)**  | • DB trigger → `pgmq` queue → Edge Function (Deno) running **gte‑small** embeddings <br>• Edge Function batch‑processes jobs; retry logic lives in `pgmq`                                                                               | Keeps the user request fast; embedding work happens off the critical path and auto‑retries on failures.                                                                         |                                                                                  |
| **6. Vector search & isolation** | • HNSW index (\`m=16                                                                                                                                                                                                                    |  ef\_construction=200`to start) <br>• Every row tagged with`tenant\_id`; RLS filters queries <br>• Raise `ef\_search\` at query time to guarantee k results after RLS filtering | High‑recall similarity search **and** hard tenant isolation—no cross‑data leaks. |
| **7. DB access & pooling**       | • All code goes through **SQLAlchemy ORM only** (lint for raw SQL) <br>• Connect via Supavisor; rely on its pool, not big local pools                                                                                                   | Keeps connection count predictable and honours RLS automatically.                                                                                                               |                                                                                  |
| **8. Scheduling**                | • APScheduler (or an `asyncio` loop) launched in FastAPI lifespan; one instance owns the job lock                                                                                                                                       | Simple, zero‑extra‑infrastructure way to run periodic crawls without Celery.                                                                                                    |                                                                                  |
| **9. Observability**             | • OpenTelemetry spans around: crawl, parse, embed, search <br>• Key KPIs in Grafana: duplicate‑URL %, crawl‑success %, embedding latency, HNSW recall                                                                                   | Lets you spot slowdowns or search‑quality drops before users do.                                                                                                                |                                                                                  |
| **10. PII handling**             | • Encrypt email / phone columns via Supabase Vault (or pgcrypto with Vault‑managed key) <br>• Audit & mask via RLS                                                                                                                      | Ensures compliance and future‑proofs data deletes/rotations.                                                                                                                    |                                                                                  |
