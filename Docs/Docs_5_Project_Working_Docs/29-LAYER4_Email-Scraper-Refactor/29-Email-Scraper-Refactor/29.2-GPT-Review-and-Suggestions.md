Below is a punch‑list of **clarifications and micro‑tweaks** that will remove the last pockets of ambiguity in the work‑order and raise the odds of “first‑try green” to ≈ 100 %. I grouped them by priority.

| #        | Area                                 | What to clarify / add                                                                                                                                                               | Why it matters                                                                                                   |
| -------- | ------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |
| **A‑1**  | **Exact router paths & names**       | Lock‑in the final endpoint names in one place (e.g. `POST /api/v3/scan/website` & `GET /api/v3/scan/status/{job_id}`) and note _file+function_ where they live.                     | Prevents the classic “code uses `/scan/emails` but docs say `/scan/website`” drift that breaks FE calls & tests. |
| **A‑2**  | **Request/response Pydantic models** | Add the concrete class names and fields, e.g. `class EmailScanRequest(BaseModel): domain_id: UUID` and `class JobStatusResponse(BaseModel): job_id: UUID; status: TaskStatus; ...`. | Lets the implementer drop them straight into `schemas/` with zero guesswork.                                     |
| **A‑3**  | **User‑ID hand‑off**                 | Decide explicitly: _pass_ `user_id` from router → task, or default to `SYSTEM_USER_ID`. Document the choice in the checklist.                                                       | Avoids “null FK” errors or mystery UUIDs in the `jobs` table.                                                    |
| **A‑4**  | **Job uniqueness / dedupe rule**     | Clarify whether kicking off a scan on a domain that already has a **RUNNING/PENDING** job should: (a) create a second job, (b) return the existing job_id, or (c) 409 Conflict.     | Drives task logic and FE UX expectations.                                                                        |
| **A‑5**  | **Email‑scrape progress contract**   | State when and how `progress` should be updated (e.g. set `0 → 1` or incremental updates every N pages).                                                                            | Without it, the task may leave `progress` at 0 until the end, making the status endpoint look broken.            |
| **A‑6**  | **Failure semantics**                | Specify what counts as “FAILED”: network error, 0 emails found, invalid domain? Should `result_data` carry partial results on failure?                                              | Prevents differing interpretations that confuse monitoring and retries.                                          |
| **A‑7**  | **Concurrency limits**               | If multiple scans run, do you need a semaphore / pool size? Add a note if the infra (Render) has memory constraints or if you rely on the job queue.                                | Avoids “works locally, OOMs in prod”.                                                                            |
| **A‑8**  | **Email validation / deduping**      | Call out whether the scraper must: • lowercase addresses • dedupe • validate with regex or DNS.                                                                                     | Changes both task logic and DB uniqueness handling.                                                              |
| **A‑9**  | **Alembic migration note**           | If the `Job` model or enum values changed recently, remind devs to run `alembic revision --autogenerate` and review.                                                                | Prevents “column does not exist” surprises in CI.                                                                |
| **A‑10** | **Automated test scope**             | State explicitly: “Creating/adjusting pytest tests **is** in scope” _or_ “not required for this ticket.”                                                                            | Ends uncertainty about time‑boxing.                                                                              |

---

## Small spec tweaks for smoother execution

1. **Add a “Success definition of done” block**

   ```text
   All acceptance tests pass • ruff passes • curl example returns 202 with job_id •
   GET status returns COMPLETE with ≥1 email in result_data after task finishes.
   ```

2. **Inline the canonical Enum import lines**

   ```python
   from src.models import TaskStatus   # ← single source of truth
   ```

3. **Embed a ready‑to‑copy DB‑enum check**

   ```sql
   SELECT unnest(enum_range(NULL::task_status)) AS value;
   ```

4. **Mention `execution_options(synchronize_session=False)`** in the row‑count bullet, so devs know exactly how to get reliable `rowcount` with asyncpg.

---

## Optional “nice‑to‑have” accelerators

| Tool                                 | Quick win                                                                                  |
| ------------------------------------ | ------------------------------------------------------------------------------------------ |
| **Ormar or SQLModel stubs in tests** | Spin up an in‑memory SQLite DB for pytest without touching Supabase.                       |
| **Factory Boy + Faker**              | Generate test `Domain` + `Contact` rows for the scraper task.                              |
| **Log‑structured JSON**              | Pipe task logs to Render’s dashboard and query by `job_id`.                                |
| **Retry decorator** (`tenacity`)     | Auto‑retry transient HTTP errors during scraping, mark job `FAILED` only after N attempts. |

---

### Bottom line

The work‑order is already thorough; adding the clarifications above removes the last “interpretation gaps” that usually trigger re‑work. Nail those details and the refactor should sail through code review and CI on the first pass.
