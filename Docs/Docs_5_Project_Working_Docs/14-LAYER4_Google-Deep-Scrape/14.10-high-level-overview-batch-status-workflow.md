# Architectural Pattern: Batch Status-Driven Enrichment Workflow

**Document ID:** 14.10-high-level-overview-batch-status-workflow.md
**Status:** Active
**Date:** 2023-04-03

## 1. Purpose

This document outlines a common architectural pattern used within the application for scenarios where:

1. A user selects multiple items from a data grid or list view.
2. An action (e.g., button click) triggers an update to the status of these selected items.
3. This status change conditionally queues the items for asynchronous background processing.
4. A background service picks up queued items, performs an action (often data enrichment involving external API calls), and saves the results back to the database.

This pattern decouples the user's immediate action from potentially long-running background tasks, providing a responsive UI while ensuring data processing occurs reliably.

## 2. Key Terminology

Understanding these terms helps in discussing and implementing this pattern:

- **Batch Update:** Processing multiple items selected by the user in a single API request and database transaction.
- **Atomic Conditional Update:** The backend API logic that updates the primary status and _conditionally_ updates a secondary status (e.g., queue status) within a single, indivisible database transaction. Ensures consistency.
- **Transactional State Transition:** Viewing the status update as a trigger that moves an item from one processing state to another (e.g., `selected` -> `queued`) within the confines of a transaction.
- **Queue-Based Asynchronous Processing:** Offloading tasks triggered by the user action to a separate background process using a queue mechanism.
- **Database Polling / DB Queue:** A specific queue implementation where the background service periodically queries the database for items marked with a specific status (e.g., `queued`).
- **Background Worker/Service:** The independent process (e.g., managed by APScheduler) responsible for executing the asynchronous tasks.
- **Data Enrichment Pipeline:** Describes the overall goal where the background task fetches additional data (often from external APIs) to augment existing records.
- **State Machine Workflow:** Viewing the entire lifecycle of an item as it moves through defined states (e.g., `New`, `Selected`, `Queued`, `Processing`, `Completed`, `Failed`) managed by both user actions and background processes.

## 3. Workflow Steps (Numbered Breakdown)

This sequence details the typical flow:

**1.0 User Initiation & API Trigger**

- **1.1** User interacts with the UI, selecting one or more items (e.g., rows in a data grid).
- **1.2** User triggers an action (e.g., clicks "Submit" or "Queue Selected").
- **1.3** The UI gathers identifiers for the selected items and constructs an API request.

**2.0 API Layer Processing (e.g., `/api/v3/[resource]/status`)**

- **2.1** Request received at the designated batch status update endpoint (typically a `PUT` or `POST`).
- **2.2** Endpoint logic performs an **Atomic Conditional Update** on the relevant database table (e.g., `places_staging`) for the specified item IDs:
  - Updates the primary `status` field based on user input.
  - **Conditionally:** If the primary status matches a predefined trigger value (e.g., `SELECTED_FOR_DEEP_SCAN`), it also updates a secondary queue status field (e.g., `deep_scan_status` to `queued`) and clears any related error field.
  - This entire update for all selected items occurs within a single database transaction.
- **2.3** API endpoint returns a success/failure response to the UI.

**3.0 Background Scheduler Activation**

- **3.1** The database state change (`[queue_status_field] = 'queued'`) marks items for processing.
- **3.2** An independent background scheduler (e.g., APScheduler) runs periodically.

**4.0 Background Processing Job Execution (e.g., `src/services/[some]_scheduler.py`)**

- **4.1** The scheduler executes its processing function (e.g., `process_pending_jobs`).
- **4.2** The function queries the database table for records where `[queue_status_field] == 'queued'` (using **Database Polling**).
- **4.3** For _each_ queued item found:
  - **4.3.1** Update the item's `[queue_status_field]` to `processing` (within a transaction).
  - **4.3.2** Trigger the core processing/enrichment logic (often a method in a separate service), passing necessary identifiers (e.g., primary key, external API key).

**5.0 Core Processing/Enrichment Service Execution (e.g., `src/services/[resource]/[resource]_service.py`)**

- **5.1** The service method receives the identifiers.
- **5.2** Performs the main task (e.g., calls an external API using an item-specific key variable).
- **5.3** Receives the result/enriched data.
- **5.4** Maps the received data to the target database model.
- **5.5** Performs a save/upsert operation into the target data table (e.g., `local_businesses`).
- **5.6** Returns success or raises an exception on failure.

**6.0 Final Status Update (within Background Scheduler Job)**

- **6.1** Back in the scheduler's processing function loop for the specific item:
  - **6.1.1 (Success Path):** If the core processing (Step 4.3.2) completed successfully:
    - Update the item's record in the source/staging table: Set `[queue_status_field]` = `completed`, Clear `[error_field]`. (Occurs in a new transaction).
  - **6.1.2 (Failure Path):** If the core processing raised an exception:
    - Catch the exception.
    - Update the item's record in the source/staging table: Set `[queue_status_field]` = `failed`, Set `[error_field]` = captured error message. (Occurs in a new transaction).

**7.0 Workflow Conclusion (for the specific item)**

- **7.1** The background job loop continues to the next queued item.
- **7.2** The background job finishes its current run.

## 4. Visual Flowchart (Mermaid)

```mermaid
graph TD
    A[User Selects Items & Triggers Action in UI] --> B{API Call};

    subgraph API Layer [2.0]
        style API Layer fill:#eee,stroke:#ccc
        B -- Request --> C(Batch Status Endpoint
e.g., `PUT /api/v3/[resource]/status`);
        C -- DB Update (Atomic Conditional) --> D[Update Source Table:
Set `status` = [user_value]
IF trigger THEN Set `queue_status` = 'queued'];
    end

    D --> E{Background Scheduler [3.0]};

    subgraph Background Processing [4.0]
        style Background Processing fill:#eee,stroke:#ccc
        E -- Periodically polls DB --> F(Scheduler Job
e.g., `process_pending_jobs`);
        F -- Finds item with `queue_status == 'queued'` --> G[Update Source Table:
Set `queue_status` = 'processing'];
        G -- Triggers Task --> H(Core Processing Service [5.0]
e.g., `process_single_item(id)`);
        subgraph Core Processing [5.0]
          style Core Processing fill:#ddd,stroke:#bbb
          H -- Calls External API --> I[External Enrichment API];
          I -- Returns Result --> H;
          H -- Maps Data --> J[Map to Target Model];
          J -- Upserts Data --> K[Save/Update Target Table];
        end
        K -- Task Complete --> F;
    end

    subgraph Final Status Update [6.0]
        style Final Status Update fill:#eee,stroke:#ccc
        F -- Success --> L[Update Source Table:
Set `queue_status` = 'completed'];
        F -- Failure --> M[Update Source Table:
Set `queue_status` = 'failed'
Set `error` = message];
    end

    L --> Z([End Workflow for Item 7.0]);
    M --> Z;

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
    style E fill:#ccf,stroke:#333,stroke-width:2px
    style Z fill:#f9f,stroke:#333,stroke-width:2px
```

## 5. Example Implementation

The **Curation-Driven Deep Scrape** feature provides a concrete example of this pattern. Refer to the following documents for details on its implementation:

- `project-docs/14-Google-Deep-Scrape/14.1-GOOGLE MAPS DEEP SCRAPE IMPLEMENTATION PLAN.md` (Especially Section 4.6)
- `project-docs/14-Google-Deep-Scrape/14.2-DEEP_SCRAPE_IMPLEMENTATION_PROGRESS.md`
- `project-docs/14-Google-Deep-Scrape/14.9-New AI-Hand-Off.md`
- Relevant Source Code:
  - `src/routers/places_staging.py` (API Endpoint)
  - `src/services/sitemap_scheduler.py` (Background Scheduler Job)
  - `src/services/places/places_deep_service.py` (Core Processing Service)
  - `src/models/place.py` (Source Table Model w/ statuses)
  - `src/models/local_business.py` (Target Table Model)

This document serves as a template and reference point for implementing similar workflows requiring batch user actions triggering asynchronous background processing and data enrichment.
