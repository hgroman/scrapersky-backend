# ScraperSky Workflow Builder Cheat Sheet

## CRITICAL NAMING CONVENTION

**THE WORKFLOW NAME DEFINES ALL NAMING CONVENTIONS THROUGHOUT THE IMPLEMENTATION**

The workflow name you choose in Phase 1 (e.g., "contact_extraction") will define:

- Database field names (`contact_extraction_curation_status`, `contact_extraction_status`)
- Enum type names (`contactextractionstatusenum`)
- Service file names (`contact_extraction_service.py`, `contact_extraction_scheduler.py`)
- UI component IDs (`contact-extraction-tab`)
- Function names (`process_contact_extraction_queue`)

This consistency is **MANDATORY** and ensures all components are correctly linked throughout the system.

---

This guide provides a step-by-step process to create a new ScraperSky workflow based on the producer-consumer pattern found throughout the system. By following these 5 phases, you can rapidly implement a standardized workflow that adheres to all architectural principles.

> **Reference:** See the [Producer-Consumer Workflow Pattern](../Docs_7_Workflow_Canon/PRODUCER_CONSUMER_WORKFLOW_PATTERN.md) document for the authoritative pattern definition.

## Overview of the 5 Phases

1. **Phase 1: Questionnaire Completion** - Define workflow purpose, source and destination tables
2. **Phase 2: Consumer Endpoint Construction** - Create CRUD endpoints for user row selection and status updates
3. **Phase 3: Background Service Implementation** - Build the status monitoring scheduler
4. **Phase 4: Curation Service Development** - Create the actual data enrichment service
5. **Phase 5: End-to-End Testing** - Verify the complete workflow

## Phase 1: Questionnaire Completion

The first phase focuses on clearly defining what your workflow is meant to accomplish.

### 1.1 Core Questions

Answer these foundation questions to define your workflow:

| Question                                    | Example Answer       | Your Answer                 |
| :------------------------------------------ | :------------------- | :-------------------------- |
| **What is the workflow name?** (snake_case) | `contact_extraction` | `page_curation`             |
| What is the purpose of the data enrichment? | Extract contacts     | Select pages for processing |
| What is the source table?                   | `pages`              | `pages`                     |
| What is the destination table?              | `contacts`           | _(Updates source)_ ยน        |

> **CRITICAL**: The workflow name you choose (e.g., `contact_extraction`) determines ALL naming patterns throughout your implementation. It must be in snake_case format and should clearly describe the workflow's purpose.

### 1.2 Additional Workflow Details

These questions help refine implementation details:

| Question                                            | Example Answer               | Your Answer                     |
| :-------------------------------------------------- | :--------------------------- | :------------------------------ |
| Will this have a UI component?                      | Yes                          | Yes                             |
| Is this a background-only process?                  | No                           | No                              |
| Does it update existing records or create new ones? | Creates new records          | Updates existing (`pages`)      |
| Estimated processing time per record                | > 5 seconds (background)     | < 1 second (API call/DB update) |
| What specific fields from source table are needed?  | page_content, url            | `id` (for selection)            |
| What verification/validation is required?           | Check for valid email format | None (Standard API validation)  |

## Phase 1 Tasks: Schema Preparation

After answering the questionnaire, complete these database schema tasks to prepare for implementation:

### 1.3 Database Schema Requirements

Add the required status fields to the source table (`pages`):

```sql
-- Add to source table (pages)
-- NOTE: Enum types must be created first (see 1.4)
ALTER TABLE pages ADD COLUMN page_curation_status pagecurationstatus NOT NULL DEFAULT 'New';
-- page_processing_status starts as NULL, only set to 'Queued' when page_curation_status becomes 'Selected'
ALTER TABLE pages ADD COLUMN page_processing_status pageprocessingstatus NULL;
ALTER TABLE pages ADD COLUMN page_processing_error TEXT NULL;
```

> **Reference:** See [Database Schema Change Guide](../Docs_1_AI_GUIDES/18-DATABASE_SCHEMA_CHANGE_GUIDE.md) for standardized table modifications.

### 1.4 Required Database Enum Types

Create both enum types in PostgreSQL **(Manual SQL Execution Required)**:

```sql
-- Curation status enum (user-driven selection)
CREATE TYPE pagecurationstatus AS ENUM ('New', 'Selected', 'Rejected', 'Archived');

-- Processing status enum (background processing trigger)
CREATE TYPE pageprocessingstatus AS ENUM ('Queued', 'Processing', 'Completed', 'Error');
```

> **Reference:** See [Enum Handling Standards](../Docs_1_AI_GUIDES/27-ENUM_HANDLING_STANDARDS.md) and [Database Enum Isolation](../Docs_1_AI_GUIDES/29-DATABASE_ENUM_ISOLATION.md).

### 1.5 Python Enum Definitions

Create/update enum classes in `src/models/enums.py` (or `src/models/page.py`):

```python
from enum import Enum

class PageCurationStatus(str, Enum):
    New = "New"
    Selected = "Selected"
    Rejected = "Rejected"
    Archived = "Archived"

class PageProcessingStatus(str, Enum):
    Queued = "Queued"
    Processing = "Processing"
    Completed = "Completed"
    Error = "Error"
```

> **Reference:** See [Enum Handling Standards](../Docs_1_AI_GUIDES/27-ENUM_HANDLING_STANDARDS.md)

## Phase 2: Consumer Endpoint Construction

This phase creates the CRUD interface for user row selection and batch updates.

### 2.1 API Request Schema

Create request models in `src/api_models/` or `src/schemas/`:

```python
class {SourceTable}BatchStatusUpdateRequest(BaseModel):
    ids: List[UUID]
    status: {SourceTable}CurationStatus
```

> **Reference:** See [API Standardization Guide](../Docs_1_AI_GUIDES/15-API_STANDARDIZATION_GUIDE.md)

### 2.2 API Router Implementation

Create router in `src/routers/pages.py`:

````python
# src/routers/pages.py
import logging
from typing import List
from uuid import UUID
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy import update
from sqlalchemy.ext.asyncio import AsyncSession

from src.db.session import get_session_dependency # Assuming session dependency setup
from src.models.page import Page # Assuming model location
from src.models.enums import PageCurationStatus, PageProcessingStatus # Assuming enum location
from src.schemas.page import PageBatchStatusUpdateRequest # Assuming schema location
from src.schemas.response import GenericResponse # Assuming generic response schema
from src.auth.jwt_auth import UserInToken, get_current_user # Assuming auth setup

router = APIRouter()
logger = logging.getLogger(__name__)

@router.put("/api/v3/pages/status", response_model=GenericResponse)
async def update_page_status_batch(
    request: PageBatchStatusUpdateRequest,
    session: AsyncSession = Depends(get_session_dependency),
    current_user: UserInToken = Depends(get_current_user),
):
    """Update the curation status for a batch of pages.

    If the target status is 'Selected', also updates the processing
    status to 'Queued' to trigger the next workflow stage.
    """
    try:
        target_curation_status = request.status
        logger.info(
            f"User {current_user.sub} updating {len(request.ids)} pages to status {target_curation_status.value}"
        )

        # --- Determine if queueing is needed based on target status ---
        should_queue_processing = (target_curation_status == PageCurationStatus.Selected)

        async with session.begin():
            # Base update values
            update_values = {
                "page_curation_status": target_curation_status
                # Add updated_by=current_user.sub if tracking is needed
            }

            # --- Apply Dual-Status Update Logic ---
            if should_queue_processing:
                logger.debug(f"Queueing pages {request.ids} for processing.")
                # If target is 'Selected', set processing status to 'Queued' and clear errors
                update_values["page_processing_status"] = PageProcessingStatus.Queued
                update_values["page_processing_error"] = None
            else:
                 # Optional: If setting to another status, clear processing status?
                 # update_values["page_processing_status"] = None
                 pass # Keep processing status as is unless explicitly clearing

            stmt = (
                update(Page)
                .where(Page.id.in_(request.ids))
                .values(**update_values)
                .returning(Page.id)
            )
            result = await session.execute(stmt)
            updated_ids = result.scalars().all()
            logger.info(f"Database update successful for {len(updated_ids)} page IDs.")

        # Construct a more informative response
        response_message = f"Updated {len(updated_ids)} page records to curation status '{target_curation_status.value}'."
        if should_queue_processing and len(updated_ids) > 0:
             response_message += f" Queued {len(updated_ids)} for processing."

        return GenericResponse(message=response_message, details={"updated_ids": updated_ids})

    except Exception as e:
        logger.exception(
            f"Error updating page status for IDs {request.ids} by user {current_user.sub}: {str(e)}",
            exc_info=True
        )
        raise HTTPException(status_code=500, detail=f"Error updating page status.")

### 2.3 Register Router in main.py

Add to `src/main.py`:

```python
from src.routers.{source_table}s import router as {source_table}_router
# ...
app.include_router({source_table}_router, tags=["{source_table.title()}s"])
````

## Phase 3: Background Service Implementation

This phase creates the monitoring service that checks for records marked as 'Queued' and processes them.

### 3.1 Background Scheduler Implementation

Create the scheduler in `src/services/{output_table}_extraction_scheduler.py`:

```python
async def process_{source_table}_queue():
    session = await get_background_session()
    try:
        # First transaction: find and lock records for processing
        async with session.begin():
            # Find records with curation status 'Queued'
            stmt = (
                select({SourceTable})
                .where({SourceTable}.{workflow_name}_curation_status == {SourceTable}CurationStatus.Queued)
                .with_for_update(skip_locked=True)
                .limit(10)  # Process in batches
            )
            result = await session.execute(stmt)
            records = result.scalars().all()

            # Mark them as 'Processing'
            if records:
                record_ids = [record.id for record in records]
                update_stmt = (
                    update({SourceTable})
                    .where({SourceTable}.id.in_(record_ids))
                    .values({workflow_name}_curation_status={SourceTable}CurationStatus.Processing)
                )
                await session.execute(update_stmt)

        # Process each record outside the transaction
        for record_id in record_ids:
            try:
                await process_single_{source_table}(session, record_id)
            except Exception as e:
                logger.error(f"Error processing {source_table} {record_id}: {str(e)}")
                # Update status to Error
                async with session.begin():
                    error_stmt = (
                        update({SourceTable})
                        .where({SourceTable}.id == record_id)
                        .values(
                            {workflow_name}_curation_status={SourceTable}CurationStatus.Error,
                            error_message=str(e)
                        )
                    )
                    await session.execute(error_stmt)

    except Exception as e:
        logger.error(f"Error in {source_table} processing scheduler: {str(e)}")
    finally:
        await session.close()
```

> **Reference:** See [Scheduled Tasks APScheduler Pattern](../Docs_1_AI_GUIDES/21-SCHEDULED_TASKS_APSCHEDULER_PATTERN.md), [Shared Scheduler Integration Guide](../Docs_1_AI_GUIDES/24-SHARED_SCHEDULER_INTEGRATION_GUIDE.md), and [Background Services Architecture](../Docs_6_Architecture_and_Status/BACKGROUND_SERVICES_ARCHITECTURE.md).

### 3.2 Register Scheduler

Add to `src/schedulers.py`:

```python
scheduler.add_job(
    process_{source_table}_queue,
    'interval',
    seconds=30,
    id=f"{output_table}_extraction_scheduler",
    replace_existing=True
)
```

> **Reference:** See [Scheduler and Settings Patterns](../Docs_1_AI_GUIDES/28-SCHEDULER_AND_SETTINGS_PATTERNS.md) for scheduler registration standards.

## Phase 4: Curation Service Development

This phase implements the core data enrichment functionality.

### 4.1 Data Enrichment Service

Create the service in `src/services/{output_table}_extraction_service.py`:

```python
async def process_single_{source_table}(
    session: AsyncSession,
    {source_table}_id: UUID,
) -> None:
    try:
        # Step 1: Retrieve the source record
        async with session.begin():
            stmt = select({SourceTable}).where({SourceTable}.id == {source_table}_id)
            result = await session.execute(stmt)
            source_record = result.scalars().first()

            if not source_record:
                raise ValueError(f"{SourceTable} with ID {source_table}_id not found")

            # Update extraction status to Processing
            source_record.{output_table}_extraction_status = {OutputTable}ExtractionStatusEnum.Processing

        # Step 2: Perform the actual data enrichment (outside transaction)
        # Example: Extract emails from page content
        extracted_data = await perform_extraction(source_record)

        # Step 3: Create output records with results
        async with session.begin():
            # Create new records in destination table
            for item in extracted_data:
                new_record = {OutputTable}(
                    id=uuid4(),
                    {source_table}_id=source_record.id,
                    # Add other fields from extracted_data
                    created_at=datetime.utcnow()
                )
                session.add(new_record)

            # Update source record status to Complete
            update_stmt = (
                update({SourceTable})
                .where({SourceTable}.id == {source_table}_id)
                .values(
                    {workflow_name}_curation_status={SourceTable}CurationStatus.Complete,
                    {output_table}_extraction_status={OutputTable}ExtractionStatusEnum.Complete,
                )
            )
            await session.execute(update_stmt)

    except Exception as e:
        # Update statuses to Error on exception
        async with session.begin():
            error_stmt = (
                update({SourceTable})
                .where({SourceTable}.id == {source_table}_id)
                .values(
                    {workflow_name}_curation_status={SourceTable}CurationStatus.Error,
                    {output_table}_extraction_status={OutputTable}ExtractionStatusEnum.Error,
                    error_message=str(e)
                )
            )
            await session.execute(error_stmt)
        raise

# Helper function for the actual data extraction
async def perform_extraction(source_record):
    # Implement your specific extraction logic here
    # Example: Extract emails from page content
    # return [{'email': 'example@domain.com', 'source_url': source_record.url}]
    pass
```

> **Reference:** See [Absolute ORM Requirement](../Docs_1_AI_GUIDES/01-ABSOLUTE_ORM_REQUIREMENT.md), [Core Architectural Principles - Error Handling](../Docs_1_AI_GUIDES/17-CORE_ARCHITECTURAL_PRINCIPLES.md#6-error-handling), and [Transaction Management Guide](../Docs_1_AI_GUIDES/13-TRANSACTION_MANAGEMENT_GUIDE.md).

### 2.4 Frontend Components (if UI-driven)

Create the necessary frontend components for user interaction:

#### 2.4.1 HTML Tab

Add to `templates/scraper-sky-mvp.html`:

```html
<div class="tab-pane" id="{workflow-name}-tab">
  <div class="container">
    <div class="row mt-3">
      <div class="col-12">
        <h4>{WorkflowName} Management</h4>
        <div class="card">
          <div class="card-header bg-primary text-white">
            {SourceTable} Selection
          </div>
          <div class="card-body">
            <table id="{source_table}-table" class="table table-striped">
              <thead>
                <tr>
                  <th>
                    <input type="checkbox" id="select-all-{source_table}s" />
                  </th>
                  <th>ID</th>
                  <th>Status</th>
                  <!-- Add other relevant fields -->
                </tr>
              </thead>
              <tbody id="{source_table}-tbody">
                <!-- Rows will be populated by JavaScript -->
              </tbody>
            </table>
          </div>
          <div class="card-footer">
            <button
              id="update-{source_table}-status-btn"
              class="btn btn-primary"
            >
              Queue Selected for Processing
            </button>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
```

#### 2.4.2 JavaScript File

Create in `static/js/{workflow-name}-tab.js`:

```javascript
$(document).ready(function() {
    // Load initial data
    load{SourceTable}Data();

    // Select all checkbox
    $('#select-all-{source_table}s').click(function() {
        $('.{source_table}-checkbox').prop('checked', $(this).prop('checked'));
    });

    // Queue button click handler
    $('#update-{source_table}-status-btn').click(function() {
        const selectedIds = getSelected{SourceTable}Ids();
        if (selectedIds.length === 0) {
            showNotification('Warning', 'Please select at least one item to process');
            return;
        }
        update{SourceTable}Status(selectedIds, '{SourceTable}CurationStatus.Queued');
    });
});

function load{SourceTable}Data() {
    $.ajax({
        url: '/api/v3/{source_table}s/list',
        type: 'GET',
        success: function(response) {
            populate{SourceTable}Table(response.items);
        },
        error: function(error) {
            showNotification('Error', 'Failed to load {source_table} data');
        }
    });
}

function populate{SourceTable}Table(items) {
    const tbody = $('#{source_table}-tbody');
    tbody.empty();

    items.forEach(item => {
        tbody.append(`
            <tr>
                <td><input type="checkbox" class="{source_table}-checkbox" data-id="${item.id}"></td>
                <td>${item.id}</td>
                <td>${item.{workflow_name}_curation_status || 'New'}</td>
                <!-- Add other fields -->
            </tr>
        `);
    });
}

function getSelected{SourceTable}Ids() {
    return $('.{source_table}-checkbox:checked').map(function() {
        return $(this).data('id');
    }).get();
}

function update{SourceTable}Status(ids, status) {
    $.ajax({
        url: '/api/v3/{source_table}s/update-status',
        type: 'POST',
        contentType: 'application/json',
        data: JSON.stringify({
            ids: ids,
            status: status
        }),
        success: function(response) {
            showNotification('Success', 'Status updated successfully');
            load{SourceTable}Data(); // Refresh the table
        },
        error: function(error) {
            showNotification('Error', 'Failed to update status');
        }
    });
}

function showNotification(title, message) {
    // Implement notification display
    alert(`${title}: ${message}`);
}
```

> **Reference:** See [Curation Workflow Operating Manual](../Docs_6_Architecture_and_Status/0.4_Curation%20Workflow%20Operating%20Manual.md) for frontend integration patterns.

## Phase 5: End-to-End Testing

The final phase validates that all components work together correctly.

### 5.1 Testing Checklist

- [ ] Database schema changes are correctly applied
- [ ] API endpoints respond with expected status codes and payloads
- [ ] Frontend UI displays correctly and sends proper requests
- [ ] Background scheduler picks up queued items
- [ ] Processing service successfully processes records
- [ ] Status fields update appropriately throughout workflow
- [ ] Error handling works as expected

### 5.2 Test Cases

```python
# Example test cases for {workflow_name} workflow

# 1. Test API endpoint
async def test_{source_table}_status_update():
    # Setup: Create test records
    async with AsyncClient(app=app, base_url="http://test") as client:
        # Execute: Update status
        response = await client.post(
            f"/api/v3/{source_table}s/update-status",
            json={"ids": [test_id], "status": "{SourceTable}CurationStatus.Queued"}
        )
        # Verify: Status code and response structure
        assert response.status_code == 200
        assert "message" in response.json()

        # Verify: Database state
        async with get_test_session() as session:
            result = await session.execute(
                select({SourceTable}).where({SourceTable}.id == test_id)
            )
            record = result.scalars().first()
            assert record.{workflow_name}_curation_status == "{SourceTable}CurationStatus.Queued"

# 2. Test processing service
async def test_process_single_{source_table}():
    # Setup: Create record with Queued status
    # Execute: Call processing function directly
    await process_single_{source_table}(test_session, test_id)
    # Verify: Record was processed and status updated
    # Verify: Output records created in destination table
```

> **Reference:** See [Comprehensive Test Plan](../Docs_1_AI_GUIDES/06-COMPREHENSIVE_TEST_PLAN.md) for testing methodology and patterns.

### 5.3 Manual Testing Procedure

1. Start the application with the scheduler enabled
2. Navigate to the workflow tab in the UI
3. Select items and queue them for processing
4. Verify status changes in UI and database
5. Check logs for expected processing messages
6. Verify destination records created correctly

## Implementation Checklist

Use this checklist to ensure all components are implemented correctly:

- [ ] **Phase 1: Definition & Schema**

  - [ ] Workflow purpose defined
  - [ ] Source and destination tables identified
  - [ ] Database enum types created
  - [ ] Status fields added to source table
  - [ ] Python enum classes defined

- [ ] **Phase 2: Consumer Endpoint**

  - [ ] API request schema created
  - [ ] Router implemented with status update endpoint
  - [ ] Router registered in main.py
  - [ ] Frontend components created (if UI-driven)

- [ ] **Phase 3: Background Service**

  - [ ] Scheduler implemented
  - [ ] Scheduler registered in schedulers.py
  - [ ] Error handling implemented

- [ ] **Phase 4: Curation Service**

  - [ ] Data enrichment service implemented
  - [ ] Transaction boundaries properly managed
  - [ ] Status updates handled correctly
  - [ ] Error cases handled gracefully

- [ ] **Phase 5: Testing**
  - [ ] Unit tests created
  - [ ] Integration tests created
  - [ ] Manual testing completed
  - [ ] Error scenarios tested

## Example: Pages to Contacts Workflow Implementation

Following the 5-phase approach for extracting emails from pages to contacts:

### Phase 1: Questionnaire & Schema

- **Purpose:** Extract contact information (emails) from web pages
- **Source table:** `pages`
- **Destination table:** `contacts`
- **Status fields:** `contact_extraction_curation_status`, `contact_extraction_status`
- **Enum types:** `pagecurationstatus`, `contactextractionstatusenum`

### Phase 2: Consumer Endpoint

- **Router:** `src/routers/pages.py` with `/api/v3/pages/update-status`
- **UI:** Contact extraction tab with page selection and queue button

### Phase 3: Background Service

- **Scheduler:** `src/services/contact_extraction_scheduler.py`
- **Registration:** Added to `src/schedulers.py`

### Phase 4: Curation Service

- **Service:** `src/services/contact_extraction_service.py`
- **Logic:** Extracts emails using regex pattern, creates contact records

### Phase 5: Testing

- **Tests:** Unit tests for email extraction, integration tests for workflow

## Additional Resources

- [Standard Curation Workflow Blueprint](../Docs_7_Workflow_Canon/BP-01-Standard_Curation_Workflow.md)
- [Curation Workflow Cookbook](<../Docs_6_Architecture_and_Status/0.5_Curation%20Workflow%20Cookbook%20(Developer%20On%E2%80%91Ramping%20Guide).md>)
- [Architecture Flow and Components](../Docs_6_Architecture_and_Status/0.1_ScraperSky_Architecture_Flow_and_Components.md)
- [Background Service Pattern and Router Crosswalk](../Docs_6_Architecture_and_Status/BACKGROUND_SERVICE_PATTERN_AND_ROUTER_CROSSWALK.md)
- [Core Architectural Principles](../Docs_1_AI_GUIDES/17-CORE_ARCHITECTURAL_PRINCIPLES.md)
