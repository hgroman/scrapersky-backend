# Work Order: Domain Curation to Sitemap Analysis Trigger

**Document ID:** 05-WORK-ORDER-DOMAIN-TO-SITEMAP
**Status:** Specification Final
**Created:** April 2025
**Author:** Gemini Assistant & User
**Related Pattern:** `02-CURATION-DRIVEN-BACKGROUND-PROCESSING-PATTERN.md` (Adapting pattern to bridge with legacy job system)
**Project Standards Reference:** Adhere strictly to `01-ABSOLUTE_ORM_REQUIREMENT.md` and `16-UUID_STANDARDIZATION_GUIDE.md`.

## ðŸš¨ CRITICAL PROJECT STANDARDS ðŸš¨

**Implementation MUST strictly adhere to the following project-wide standards defined in `Docs/Docs_1_AI_GUIDES/`:**

1.  **`01-ABSOLUTE_ORM_REQUIREMENT.md`**: **NO RAW SQL.** All database interactions MUST use the SQLAlchemy ORM. The `raw_sql=true` connection parameter is ONLY for Supavisor compatibility configuration and NEVER permits raw SQL in application logic.
2.  **`16-UUID_STANDARDIZATION_GUIDE.md`**: Use standard UUIDs (specifically `UUID4` from Pydantic for models, `PGUUID` for SQLAlchemy) for all primary keys and foreign keys as applicable.
3.  **Connection Pooling**: Utilize the existing Supavisor connection pool configuration as defined in `README.md` and environment settings.
4.  **Scheduler Configuration**: The modified scheduler (`src/services/sitemap_scheduler.py`) is configured via environment variables (e.g., `SITEMAP_SCHEDULER_INTERVAL_MINUTES`, `SITEMAP_SCHEDULER_BATCH_SIZE`) defined in `docker-compose.yml` and `.env`. The implementation should respect these existing configuration patterns.
5.  **Docker Environment**: The application runs within a Docker container managed by `docker-compose.yml`. All necessary environment variables (database connections, API keys like `DEV_TOKEN` needed for the adapter service's internal API call, scheduler settings) are injected via this file and accessed through the application's `settings` configuration. Ensure the adapter service correctly retrieves any required API keys/tokens from the environment configuration.

**Failure to comply with these standards will result in rejection of the work.**

## 1. Objective

To implement a workflow where users can review processed domains within a new UI tab, select specific domains for sitemap analysis using a new curation status field (`sitemap_curation_status`), and have this selection trigger a background process. This background process (Adapter Service) will monitor a corresponding analysis status field (`sitemap_analysis_status`) and, upon detecting a `queued` state, will interface with the existing legacy sitemap job system by submitting the selected domains via an HTTP POST request to the `POST /api/v3/sitemap/scan` endpoint.

## 2. Specification Table

This table outlines the components for the new pattern, adapting the Curation-Driven pattern to act as an adapter for the existing sitemap job system.

| Component Category          | Specification (`domains` -> Sitemap Analysis via Legacy Job System)                                                                                                                    | Notes / Decisions Made                                                                                                                                 |
| :-------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------- |
| **User Goal**               | Select processed domains for detailed sitemap scraping and analysis via a dedicated UI tab.                                                                                            | Confirmed. This stage follows the initial domain metadata extraction/processing.                                                                       |
| **Data Source Table**       | `domains`                                                                                                                                                                              | Confirmed.                                                                                                                                             |
| **Data Source Model**       | `src/models/domain.py` (`Domain`)                                                                                                                                                      | Confirmed.                                                                                                                                             |
| **User-Facing Status**      | **New Field:** `sitemap_curation_status` (Uses **New Enum:** `SitemapCurationStatusEnum`)                                                                                              | Add `sitemap_curation_status` column (type `SitemapCurationStatusEnum`, nullable, default `New`) to `domains` table. See Section 3.1 for Enum def.     |
| **Trigger Status Value**    | `Selected` (Value in `SitemapCurationStatusEnum`)                                                                                                                                      | Setting `domains.sitemap_curation_status` to `Selected` via the API will trigger setting `sitemap_analysis_status` to `queued`.                        |
| **Background Status Field** | **New Field:** `sitemap_analysis_status` (using **New Enum:** `SitemapAnalysisStatusEnum`)                                                                                             | Add `sitemap_analysis_status` column (type `SitemapAnalysisStatusEnum`, nullable) to `domains` table. See Section 3.1 for Enum def.                    |
| **Background Error Field**  | **New Field:** `sitemap_analysis_error`                                                                                                                                                | Add `sitemap_analysis_error` column (type `TEXT`, nullable) to `domains` table. Stores errors from the _adapter service_ only.                         |
| **Frontend UI**             | **New Tab (4th position, "Domain Curation")** in `static/google-maps.html`. Functionally duplicates previous curation tabs.                                                            | Data grid for `domains`, filters, pagination, batch controls. Initial filter: `sitemap_curation_status = 'New'`. See Section 3.5 for details.          |
| **API Endpoint (Read)**     | **New Endpoint:** `GET /api/v3/domains` in **New Router File:** `src/routers/domains.py`. (Paginated, Filterable by `sitemap_curation_status`, Sortable).                              | Supports the new UI tab. Requires Pydantic response models (`DomainRecord`, `PaginatedDomainResponse`).                                                |
| **API Endpoint (Update)**   | **New Endpoint:** `PUT /api/v3/domains/sitemap-curation/status` in **New Router File:** `src/routers/domains.py`.                                                                      | Handles batch updates to `sitemap_curation_status`. See Section 3.3 for logic.                                                                         |
| **API Request Model**       | **New Model:** `DomainBatchCurationStatusUpdateRequest` (in `src/models/api_models.py`).                                                                                               | Fields: `domain_ids: List[UUID]`, `sitemap_curation_status: SitemapCurationStatusApiEnum`. See Section 3.3.                                            |
| **API Input Enum**          | **New Enum:** `SitemapCurationStatusApiEnum` (in `src/models/api_models.py`).                                                                                                          | Values: `New`, `Selected`, `Maybe`, `Not a Fit`, `Archived`. Mirrors DB Enum `SitemapCurationStatusEnum`. See Section 3.3.                             |
| **Endpoint Logic (Update)** | Map API Enum -> DB Enum. For each domain, update `sitemap_curation_status`. **IF** `sitemap_curation_status` is set to `Selected`, **THEN** set `sitemap_analysis_status` to `queued`. | Implement in `update_domain_sitemap_curation_status_batch` function within `src/routers/domains.py`. Use ORM only.                                     |
| **Background Scheduler**    | **New Dedicated Scheduler Service/Function** (e.g., in **New File:** `src/services/domain_sitemap_submission_scheduler.py`).                                                           | This new scheduler polls `domains` for `sitemap_analysis_status = 'queued'` and triggers the Adapter Service task. Independent of existing schedulers. |
| **Background Worker**       | **New Adapter Service:** `DomainToSitemapAdapterService.submit_domain_to_legacy_sitemap` in **New File:** `src/services/domain_to_sitemap_adapter_service.py`.                         | Logic: Fetch `Domain` by ID, call `POST /api/v3/sitemap/scan` via `httpx`, update `sitemap_analysis_status` to `submitted` or `failed`.                |
| **Target System**           | Legacy Sitemap Job System (via `POST /api/v3/sitemap/scan` endpoint).                                                                                                                  | The adapter service acts as a bridge. The status `submitted` indicates successful handoff.                                                             |
| **Target Action**           | Create new legacy sitemap `Job` record via existing `POST /api/v3/sitemap/scan` endpoint.                                                                                              | Confirmed. Final success/failure of sitemap analysis is tracked in the legacy `Job` record, not reflected back to `sitemap_analysis_status`.           |
| **ORM Requirement**         | Yes (Strictly Enforced as per `01-ABSOLUTE_ORM_REQUIREMENT.md`).                                                                                                                       | Confirmed. No raw SQL allowed in application code.                                                                                                     |
| **UUID Requirement**        | Yes (Strictly Enforced as per `16-UUID_STANDARDIZATION_GUIDE.md`).                                                                                                                     | Confirmed. Use standard UUID format and types.                                                                                                         |

## 3. Detailed Requirements & Decisions

### 3.1 Database Schema Changes

- **Define Enums (SQL):**

  - **Action:** Execute the following SQL commands sequentially in the Supabase SQL Editor.

    **Command 1: Create Sitemap Curation Status Enum**

    ```sql
    DO $$
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'SitemapCurationStatusEnum') THEN
            CREATE TYPE public."SitemapCurationStatusEnum" AS ENUM (
                'New', 'Selected', 'Maybe', 'Not a Fit', 'Archived'
            );
            RAISE NOTICE 'Enum type "SitemapCurationStatusEnum" created.';
        ELSE
            RAISE NOTICE 'Enum type "SitemapCurationStatusEnum" already exists, skipping creation.';
        END IF;
    END$$;
    ```

    **Command 2: Create Sitemap Analysis Status Enum**

    ```sql
    DO $$
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'SitemapAnalysisStatusEnum') THEN
            CREATE TYPE public."SitemapAnalysisStatusEnum" AS ENUM (
                'queued', 'processing', 'submitted', 'failed' -- 'completed' omitted intentionally
            );
            RAISE NOTICE 'Enum type "SitemapAnalysisStatusEnum" created.';
        ELSE
            -- Ensure 'submitted' value exists if enum was already present
            ALTER TYPE public."SitemapAnalysisStatusEnum" ADD VALUE IF NOT EXISTS 'submitted';
            RAISE NOTICE 'Enum type "SitemapAnalysisStatusEnum" already exists or was altered.';
        END IF;
    END$$;
    ```

- **`domains` Table:**

  - **Action:** Execute the following SQL commands sequentially in the Supabase SQL Editor.

    **Command 3: Add Columns to `domains` Table**

    ```sql
    -- Add the USER curation status column
    ALTER TABLE public.domains
        ADD COLUMN IF NOT EXISTS sitemap_curation_status public."SitemapCurationStatusEnum" NULL DEFAULT 'New';

    -- Add columns for the BACKGROUND sitemap analysis task
    ALTER TABLE public.domains
        ADD COLUMN IF NOT EXISTS sitemap_analysis_status public."SitemapAnalysisStatusEnum" NULL,
        ADD COLUMN IF NOT EXISTS sitemap_analysis_error TEXT NULL;

    SELECT 'Columns sitemap_curation_status, sitemap_analysis_status, sitemap_analysis_error added successfully (if they did not exist).' as result;
    ```

    **Command 4: Add Indexes**

    ```sql
    CREATE INDEX IF NOT EXISTS idx_domains_sitemap_curation_status ON public.domains (sitemap_curation_status);
    CREATE INDEX IF NOT EXISTS idx_domains_sitemap_analysis_status ON public.domains (sitemap_analysis_status);

    SELECT 'Indexes for sitemap_curation_status and sitemap_analysis_status created successfully (if they did not exist).' as result;
    ```

### 3.2 Model Changes (`src/models/domain.py`)

- **Action:** Add the following Python Enum definitions and SQLAlchemy mapped columns to the `src/models/domain.py` file.

  ```python
  import enum
  from sqlalchemy import Column, String, UUID, JSON, Text, Boolean, ARRAY, DateTime, Integer, ForeignKey
  from sqlalchemy.sql import func
  from .base import Base, BaseModel
  from sqlalchemy.dialects.postgresql import UUID as PGUUID, JSONB
  from sqlalchemy import Enum as SQLAlchemyEnum # Ensure Enum is imported

  # ... other imports ...

  # Python Enum for USER curation status
  class SitemapCurationStatusEnum(enum.Enum):
      New = "New"
      Selected = "Selected"
      Maybe = "Maybe"
      Not_a_Fit = "Not a Fit" # Match API potentially needed space
      Archived = "Archived"

  # Python Enum for BACKGROUND task status
  class SitemapAnalysisStatusEnum(enum.Enum):
      queued = "queued"
      processing = "processing"
      submitted = "submitted" # Handoff to legacy system
      failed = "failed"

  class Domain(Base, BaseModel):
      __tablename__ = "domains"

      # ... existing columns ...

      # --- New fields for Sitemap Curation and Analysis --- #
      sitemap_curation_status = Column(SQLAlchemyEnum(SitemapCurationStatusEnum, name="SitemapCurationStatusEnum", create_type=False), nullable=True, default=SitemapCurationStatusEnum.New, index=True)
      sitemap_analysis_status = Column(SQLAlchemyEnum(SitemapAnalysisStatusEnum, name="SitemapAnalysisStatusEnum", create_type=False), nullable=True, index=True)
      sitemap_analysis_error = Column(Text, nullable=True)
      # ---------------------------------------------------- #

      # ... relationships and methods ...
  ```

### 3.3 API Changes

- **Action: Create New Router File:** `src/routers/domains.py`.
  - Define `router = APIRouter(prefix="/api/v3/domains", tags=["Domains"])`.
- **Action: Implement `GET /` Endpoint:** in `src/routers/domains.py`.
  - Function signature: `async def list_domains(...)`.
  - Implement standard pagination (page, size), filtering (including `sitemap_curation_status`), and sorting.
  - Use `DomainRecord` and `PaginatedDomainResponse` Pydantic models (defined below).
  - Adhere strictly to ORM-only principles.
- **Action: Implement `PUT /sitemap-curation/status` Endpoint:** in `src/routers/domains.py`.
  - Function signature: `async def update_domain_sitemap_curation_status_batch(...)`.
  - Accept `DomainBatchCurationStatusUpdateRequest` (defined below).
  - Inject `session: AsyncSession` and `current_user: Dict` dependencies.
  - Map `SitemapCurationStatusApiEnum` from request to `SitemapCurationStatusEnum` for DB update.
  - Fetch `Domain` objects using `domain_ids` from the request.
  - Within a transaction (`async with session.begin():`):
    - Loop through fetched `Domain` objects.
    - Update `domain.sitemap_curation_status` to the mapped DB enum value.
    - **If** the new `domain.sitemap_curation_status` is `SitemapCurationStatusEnum.Selected`:
      - Set `domain.sitemap_analysis_status = SitemapAnalysisStatusEnum.queued`.
      - Set `domain.sitemap_analysis_error = None`.
  - Return a dictionary with counts: `{"updated_count": ..., "queued_count": ...}`.
  - Adhere strictly to ORM-only principles.
- **Action: Register Router:** Add `from .routers.domains import router as domains_api_router` and `app.include_router(domains_api_router)` to `src/main.py`.
- **Action: Define Pydantic Models:** Add the following to `src/models/api_models.py`.

  ```python
  from pydantic import BaseModel, Field, UUID4
  from typing import List, Optional
  from datetime import datetime
  import enum

  # Import DB Enums required for response/request models
  from .domain import SitemapCurationStatusEnum, SitemapAnalysisStatusEnum

  # --- Models for Domain Curation --- #

  # Mirrors DB Enum SitemapCurationStatusEnum for API Input
  class SitemapCurationStatusApiEnum(str, enum.Enum):
      New = "New"
      Selected = "Selected"
      Maybe = "Maybe"
      Not_a_Fit = "Not a Fit"
      Archived = "Archived"

  # Request model for the batch update endpoint
  class DomainBatchCurationStatusUpdateRequest(BaseModel):
      domain_ids: List[UUID4] = Field(..., min_length=1, description="List of one or more Domain UUIDs to update.")
      sitemap_curation_status: SitemapCurationStatusApiEnum = Field(..., description="The new curation status to set for the sitemap workflow.")

  # Pydantic model mirroring Domain for API responses (adjust fields as needed for UI)
  class DomainRecord(BaseModel):
      id: UUID4
      domain: str
      sitemap_curation_status: Optional[SitemapCurationStatusEnum] = None
      sitemap_analysis_status: Optional[SitemapAnalysisStatusEnum] = None
      sitemap_analysis_error: Optional[str] = None
      # Include other relevant Domain fields needed by the UI grid
      status: Optional[str] = None # Example: original domain status
      created_at: datetime
      updated_at: datetime

      class Config:
          from_attributes = True
          use_enum_values = True # Return enum values as strings

  # Standard paginated response wrapper
  class PaginatedDomainResponse(BaseModel):
      items: List[DomainRecord]
      total: int
      page: int
      size: int
      pages: int

  # --- End Models for Domain Curation --- #
  ```

### 3.4 Background Processing Changes

- **Action: Create New Service File:** `src/services/domain_to_sitemap_adapter_service.py`.
  - Requires `httpx` library (`pip install httpx`). Ensure it is added to `requirements.txt`.
- **Action: Implement Adapter Service:** within the new file.

  ```python
  import logging
  from uuid import UUID
  import httpx # Required for making HTTP requests
  from sqlalchemy.ext.asyncio import AsyncSession
  from sqlalchemy.future import select

  from src.models.domain import Domain, SitemapAnalysisStatusEnum
  from src.config.settings import settings # Assuming settings holds API key/base URL
  from src.db.session import get_session # Example if needed standalone

  logger = logging.getLogger(__name__)

  # Define the base URL for the internal API call
  # TODO: Consider moving this to settings
  INTERNAL_API_BASE_URL = "http://localhost:8000" # Or appropriate service name in Docker network

  class DomainToSitemapAdapterService:
      "
      Service to bridge the Domain Curation status with the legacy Sitemap Job system.
      It fetches domains queued for sitemap analysis and submits them to the
      POST /api/v3/sitemap/scan endpoint.
      "

      async def submit_domain_to_legacy_sitemap(
          self,
          domain_id: UUID,
          session: AsyncSession
      ) -> bool:
          "
          Fetches a Domain, calls the legacy POST /api/v3/sitemap/scan endpoint,
          and updates the domain's sitemap_analysis_status based on the outcome.

          Args:
              domain_id: The UUID of the Domain record.
              session: The SQLAlchemy AsyncSession (expects transaction managed by caller).

          Returns:
              True if the domain was successfully submitted to the legacy endpoint,
              False otherwise.
          "
          logger.info(f"Adapter Service: Processing domain {domain_id} for sitemap submission.")
          domain: Optional[Domain] = None
          try:
              # 1. Fetch the Domain record (within the caller's transaction)
              stmt = select(Domain).where(Domain.id == domain_id)
              result = await session.execute(stmt)
              domain = result.scalar_one_or_none()

              if not domain:
                  logger.error(f"Adapter Service: Domain not found for id: {domain_id}")
                  # No domain means nothing to process, but not a failure of the service itself
                  # Consider if this case needs specific handling or just ignore
                  return False # Indicate domain wasn't processed

              if not domain.domain:
                  logger.error(f"Adapter Service: Domain record {domain_id} has no domain name.")
                  domain.sitemap_analysis_status = SitemapAnalysisStatusEnum.failed
                  domain.sitemap_analysis_error = "Domain record is missing the domain name."
                  await session.flush()
                  return False

              # 2. Prepare payload for the legacy endpoint
              scan_payload = {
                  "base_url": domain.domain,
                  # Add other parameters like max_pages if needed/configurable
                  # "max_pages": 1000
              }

              # 3. Make HTTP POST request to the legacy endpoint
              # Use an async HTTP client like httpx
              # Ensure proper authentication using the DEV_TOKEN specified in README.md
              api_key = settings.DEV_TOKEN
              headers = {
                  'Authorization': f'Bearer {api_key}',
                  'Content-Type': 'application/json'
              }
              scan_endpoint = f"{INTERNAL_API_BASE_URL}/api/v3/sitemap/scan"

              async with httpx.AsyncClient() as client:
                  logger.info(f"Adapter Service: Calling {scan_endpoint} for domain {domain.domain} ({domain_id})")
                  response = await client.post(scan_endpoint, json=scan_payload, headers=headers, timeout=30.0)

              # 4. Check response and update status
              if response.status_code == 202: # 202 Accepted is expected
                  logger.info(f"Adapter Service: Successfully submitted domain {domain.domain} ({domain_id}) to legacy sitemap scan. Status code: {response.status_code}")
                  domain.sitemap_analysis_status = SitemapAnalysisStatusEnum.submitted
                  domain.sitemap_analysis_error = None # Clear any previous error
                  await session.flush()
                  return True
              else:
                  error_detail = "Unknown error"
                  try:
                      error_detail = response.json().get("detail", error_detail)
                  except Exception:
                      error_detail = response.text
                  logger.error(f"Adapter Service: Failed to submit domain {domain.domain} ({domain_id}) to legacy sitemap scan. Status code: {response.status_code}. Response: {error_detail}")
                  domain.sitemap_analysis_status = SitemapAnalysisStatusEnum.failed
                  domain.sitemap_analysis_error = f"Failed to call /scan endpoint. Status: {response.status_code}. Detail: {error_detail[:500]}"
                  await session.flush()
                  return False

          except httpx.RequestError as http_err:
              logger.error(f"Adapter Service: HTTP request error submitting domain {domain.domain if domain else domain_id}: {http_err}", exc_info=True)
              if domain: # Check if domain was fetched before error
                  domain.sitemap_analysis_status = SitemapAnalysisStatusEnum.failed
                  domain.sitemap_analysis_error = f"HTTP Request Error: {str(http_err)}"
                  await session.flush()
              return False
          except Exception as e:
              logger.error(f"Adapter Service: Unexpected error processing domain {domain.domain if domain else domain_id}: {e}", exc_info=True)
              if domain: # Check if domain was fetched before error
                  try:
                      domain.sitemap_analysis_status = SitemapAnalysisStatusEnum.failed
                      domain.sitemap_analysis_error = f"Unexpected Adapter Error: {str(e)[:500]}"
                      await session.flush()
                  except Exception as update_err:
                      logger.error(f"Adapter Service: Failed to update domain status after unexpected error: {update_err}")
              return False
  ```

- **Action: Create New Scheduler Service:** Create a new file, e.g., `src/services/domain_sitemap_submission_scheduler.py`.
  - This service will run periodically (e.g., using APScheduler added to the main application or as a separate scheduled task/process).
  - Define a function within this file, e.g., `process_pending_domain_sitemap_submissions()`.
  - **Logic for `process_pending_domain_sitemap_submissions()`:**
    - Obtain configuration settings (batch size, potentially max instances if using APScheduler with `max_instances=1`). Define new environment variables for this scheduler (e.g., `DOMAIN_SITEMAP_SCHEDULER_INTERVAL_MINUTES`, `DOMAIN_SITEMAP_SCHEDULER_BATCH_SIZE`).
    - Acquire a database session (e.g., using `get_background_session`).
    - Query the `domains` table for records where `sitemap_analysis_status == SitemapAnalysisStatusEnum.queued`.
      - Use `ORDER BY updated_at ASC`.
      - Apply `.limit(batch_size)`.
      - Crucially, use `.with_for_update(skip_locked=True)` to prevent race conditions if multiple instances run (though `max_instances=1` is recommended).
    - Instantiate the `DomainToSitemapAdapterService`.
    - Loop through the fetched domains:
      - Log the start of processing for the domain ID.
      - **Crucially, within a transaction block for each domain:**
        - Update the domain's `sitemap_analysis_status` to `SitemapAnalysisStatusEnum.processing` immediately before calling the adapter.
      - Call `adapter_service.submit_domain_to_legacy_sitemap(domain_id=domain.id, session=session)`. The adapter service handles updating the status to `submitted` or `failed` internally.
      - Handle potential exceptions during the loop (e.g., failure to update to `processing`, error calling the adapter not caught _within_ the adapter). Attempt to mark the domain as `failed` if an unexpected error occurs in this scheduler loop.
    - Log summary statistics (e.g., number found, number attempted, number successfully submitted by adapter - though success is determined within the adapter call).
  - **Integration:** Ensure this new scheduler function is registered and triggered periodically (e.g., add it to the APScheduler setup in `main.py` or similar application entry point, using its specific interval setting).

### 3.5 Frontend Changes (`static/google-maps.html`)

- **Action: Add Tab 4 Navigation:** Add a new `<li class="nav-item">` and `<button>` for "Domain Curation" within the `<ul class="nav nav-tabs" id="mainTabs">` element, positioned as the 4th tab.
- **Action: Add Tab 4 Pane:** Add a new `<div class="tab-pane fade" id="domainCurationTab" role="tabpanel">` within the `<div class="tab-content">`.
- **Action: Implement Tab 4 UI:** Inside the `domainCurationTab` div, create the UI structure. **The look, feel, and specific component behavior (dropdowns, badges, pagination, filtering logic) MUST exactly match the existing Curation Tabs (1-3) in this file (`static/google-maps.html`) and conform to any established UI standards documented within the `project-docs` directory (e.g., `project-docs/07-UI-FIX-DOCUMENTATION/` if applicable).**
  - Filters section (e.g., dropdown for `sitemap_curation_status`, text input for domain name).
  - Data grid table (`<table id="domainCurationTable">`) with `<thead>` and `<tbody id="domainCurationTableBody">`.
    - **Columns:** Checkbox, Domain, Sitemap Curation Status, Sitemap Analysis Status, Analysis Error, Updated At.
- **Action: Add JavaScript Logic:**
  - Add variables for new UI elements.
  - Create `fetchDomainCurationData(page = 1)` function (similar to `fetchLocalBusinessData`): Calls `GET /api/v3/domains` with filters and pagination, updates table and pagination controls.
  - Create `renderDomainCurationTable(items)` function: Populates the `domainCurationTableBody` with data rows.
  - Adapt selection logic (`selectedDomainIds` Set, `handleDomainCurationRowSelection`, `updateDomainCurationBatchControls`, `clearDomainCurationSelection`).
  - Create `batchUpdateDomainCurationStatus()` function: Calls `PUT /api/v3/domains/sitemap-curation/status` with selected IDs and status, handles response, refreshes data.
  - Add event listeners for filters, pagination, selection, and batch update button.
  - Ensure the new tab fetches data when clicked (update the main tab switching logic if necessary).

## 4. Implementation Sequence (Backend First)

1.  **Models & Enums:** Update `src/models/domain.py`, define Pydantic models in `src/models/api_models.py`.
2.  **Adapter Service:** Create and implement `src/services/domain_to_sitemap_adapter_service.py`. Install `httpx`.
3.  **API Router:** Create `src/routers/domains.py`, implement `GET /` and `PUT /sitemap-curation/status` endpoints. Register router in `main.py`.
4.  **New Scheduler Service:** Create `src/services/domain_sitemap_submission_scheduler.py`, implement the polling function, define configuration, and integrate it into the application's scheduling mechanism (e.g., APScheduler in `main.py` or similar application entry point, using its specific interval setting).
5.  **Testing:** Test API endpoints (`curl`), manually set `sitemap_analysis_status` to `queued` in DB, trigger **new** scheduler, verify DB updates (`sitemap_analysis_status` to `processing`, then `submitted`/`failed`), check logs, verify calls to `POST /api/v3/sitemap/scan` are made and corresponding legacy `Job` records are created.
6.  **Frontend Implementation:** Build Tab 4 UI and JavaScript logic in `static/google-maps.html`.

---

**(Work Order Drafted - Ready for Review/Implementation)**
