# Work Order: Correct Domain Sitemap Count Aggregation

**Version:** 1.0
**Date:** 2025-04-18
**Status:** Open
**Assignee:** TBD
**Related Files:** `src/services/sitemap/processing_service.py`, `project-docs/36-Sitemap-Scheduler-Investigation/36.1-Investigate-Stuck-Sitemap-Analysis-Job.md`

## 1. Objective

Modify the sitemap processing logic to ensure the `total_sitemaps` and `sitemap_urls` fields in the `domains` table accurately reflect the aggregated totals derived from all associated records in the `sitemap_files` table, rather than just the results of the most recent scan.

## 2. Background & Context

During the investigation documented in [Work Order 36.1](project-docs/36-Sitemap-Scheduler-Investigation/36.1-Investigate-Stuck-Sitemap-Analysis-Job.md), a discrepancy was noted in the `domains` table for `ohsu.edu`. While the `sitemap_files` table correctly contained multiple entries (resulting from different scans finding the same sitemap URL), the `total_sitemaps` and `sitemap_urls` counts on the `domains` record only reflected the results of the _last_ completed scan job.

Analysis of `src/services/sitemap/processing_service.py` (specifically within the `process_domain_with_own_session` function, around line 640) revealed that the `update(Domain)` statement overwrites the counts using variables (`len(stored_sitemaps)`, `total_url_count`) that are local to the current function execution. This prevents accurate aggregation of counts over time if a domain is scanned multiple times.

## 3. Requirements

- When a sitemap scan job completes for a domain (`process_domain_with_own_session`):
  - The `domains.total_sitemaps` field should be updated to reflect the total count of distinct sitemap URLs found for that `domain_id` in the `sitemap_files` table.
  - The `domains.sitemap_urls` field should be updated to reflect the sum of `url_count` from all related `sitemap_files` records for that `domain_id`.
  - The `domains.last_scan` field should still be updated to the completion time of the current job.

## 4. Proposed Solution

Modify STEP 4 in `src/services/sitemap/processing_service.py` (`process_domain_with_own_session` function):

1.  **Remove reliance on local variables:** Stop using `len(stored_sitemaps)` and `total_url_count` directly in the `update(Domain)` statement.
2.  **Query Aggregated Counts:** After the loop processing individual sitemaps (within the `async with get_background_session() as session:` block for the update), perform two aggregate queries on the `sitemap_files` table, filtered by `domain_id=domain_obj.id`:
    - `SELECT COUNT(DISTINCT url) FROM sitemap_files WHERE domain_id = :domain_id` to get the true `total_sitemaps`.
    - `SELECT SUM(url_count) FROM sitemap_files WHERE domain_id = :domain_id` to get the true `total_urls`.
3.  **Update Domain:** Use the results from these aggregate queries in the `update(Domain).values(...)` call for the `total_sitemaps` and `sitemap_urls` fields. Ensure appropriate handling if the aggregate queries return `None` (e.g., default to 0).

## 5. Acceptance Criteria

- Run a sitemap scan for a specific domain multiple times.
- After each scan completes, verify the `domains` record for that domain:
  - `total_sitemaps` accurately reflects the count of unique sitemap URLs stored in `sitemap_files` for that domain.
  - `sitemap_urls` accurately reflects the sum of `url_count` from all related `sitemap_files` records.
  - `last_scan` reflects the timestamp of the most recent scan completion.
