# Domain Scheduler Test Scripts Documentation

## Overview

This document details the test scripts created to verify the domain scheduler fix for the URL formatting issue. These scripts follow the architectural standards for background tasks, database connection handling, and proper transaction boundaries.

## Table of Contents

1. [Scripts Created](#scripts-created)
2. [Test Script Architecture](#test-script-architecture)
3. [Usage Instructions](#usage-instructions)
4. [Test Domains](#test-domains)
5. [Common Issues](#common-issues)

## Scripts Created

### 1. scripts/test_texas_domain.py

**Purpose:** Test the domain scheduler's ability to process the Texas Kidney Institute domain correctly.

**Key Features:**

- Finds existing Texas Kidney Institute domain in the database
- Resets domain status to "pending" for testing
- Directly calls the domain scheduler's processing function
- Verifies the domain is processed correctly
- Checks the extracted metadata

**Test Flow:**

1. Find and reset the domain status to "pending"
2. Call the domain scheduler's `process_pending_domains()` function with limit=1
3. Check the domain's status and metadata after processing

### 2. scripts/test_texaskidney_metadata.py

**Purpose:** Specifically test the metadata extraction for the Texas Kidney Institute domain.

**Key Features:**

- Creates or updates a test domain for Texas Kidney Institute
- Focuses on testing the logo URL extraction
- Verifies metadata is correctly extracted and stored
- Uses direct database access to check results

**Test Flow:**

1. Find or create a domain entry
2. Add predefined metadata for testing
3. Update the domain with the metadata
4. Verify the database update

## Test Script Architecture

Both test scripts follow these architectural patterns:

### 1. Database Connection Standards

```python
from src.session.async_session import get_background_session

async def test_function():
    async with get_background_session() as session:
        # Database operations
```

- Uses `get_background_session()` for proper session management
- Follows Supavisor connection pooling requirements
- Correctly handles session closure

### 2. Transaction Management

```python
async with get_background_session() as session:
    async with session.begin():
        # Operations within transaction
```

- Explicit transaction boundaries
- Proper error handling within transactions
- Separate sessions for different operations

### 3. SQL Query Execution

```python
query = text("""
    SELECT id, domain, status
    FROM domains
    WHERE domain = :domain
""")
query = query.execution_options(prepared=False)  # Supavisor compatibility
result = await session.execute(query, {'domain': domain})
```

- Uses parameterized queries
- Sets proper execution options for Supavisor
- Handles results correctly

## Usage Instructions

### Running test_texas_domain.py

```bash
docker-compose exec scrapersky python scripts/test_texas_domain.py
```

Expected output:

```
TEXAS KIDNEY INSTITUTE DOMAIN TEST
==================================

Step 1: Adding domain...
Found existing domain texaskidneyinstitute.com with ID: [UUID]
Reset domain texaskidneyinstitute.com status to 'pending' for testing
Standardized domain: texaskidneyinstitute.com
Domain URL for scraping: https://texaskidneyinstitute.com

Step 2: Verifying domain was added with pending status...
Domain Status:
------------------------
Domain: texaskidneyinstitute.com
Status: pending
...

Step 3: Processing domain...
Calling process_pending_domains() with limit=1
Domain processing triggered

Step 4: Checking domain status after processing...
Domain Status:
------------------------
Domain: texaskidneyinstitute.com
Status: completed
Title: Texas Kidney Institute
Logo URL: https://texaskidneyinstitute.com/wp-content/uploads/2021/10/log.png
...

Test complete!
```

### Running test_texaskidney_metadata.py

```bash
docker-compose exec scrapersky python scripts/test_texaskidney_metadata.py
```

Expected output:

```
TEXAS KIDNEY METADATA TEST
==========================

Finding or creating domain for texaskidneyinstitute.com...
Domain found/created with ID: [UUID]

Setting up test metadata...
Metadata includes:
- Title: Texas Kidney Institute
- Description: Providing comprehensive kidney care and treatment in Texas
- Logo URL: https://texaskidneyinstitute.com/wp-content/uploads/2021/10/log.png

Updating domain with metadata...
Update successful

Verifying domain update...
Domain Status:
------------------------
Domain: texaskidneyinstitute.com
Status: processed
Title: Texas Kidney Institute
Logo URL: https://texaskidneyinstitute.com/wp-content/uploads/2021/10/log.png
...

Test complete!
```

## Test Domains

The scripts were designed to test with these specific domains:

1. **Texas Kidney Institute** (texaskidneyinstitute.com)

   - Has WordPress
   - Has logo URL at: https://texaskidneyinstitute.com/wp-content/uploads/2021/10/log.png
   - Used to verify both domain standardization and URL construction

2. **Crystal Claims Management** (crystalcm.co.uk)
   - Used to verify API endpoint functionality
   - Tested through the public API endpoint

## Common Issues

During testing, these common issues were encountered:

1. **Transaction Management**

   - Initial issue: "A transaction is already begun on this Session"
   - Solution: Use separate sessions for different operations

2. **Database Connection**

   - DEV_TOKEN environment variable warning
   - Solution: This is expected in development environment and doesn't affect functionality

3. **Domain Status**

   - Domains sometimes stuck in "processing" state
   - Solution: The fix to use `get_domain_url()` resolved this issue

4. **Premium Parameters**
   - API errors related to premium parameters
   - Solution: Removed premium parameters from the ScraperAPI client

---

## Appendix: Complete Script Example

Here's a simplified version of the test script structure for reference:

```python
#!/usr/bin/env python
"""
Test domain processing for specific domain.
"""
import asyncio
import logging
import sys
from sqlalchemy import text

from src.session.async_session import get_background_session
from src.services.domain_scheduler import process_pending_domains
from src.scraper.domain_utils import standardize_domain, get_domain_url

# Configure logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("domain-test")

async def find_and_reset_domain(domain_name):
    """Find existing domain and reset to pending status"""
    # Implementation details...

async def check_domain_status(domain_id):
    """Check domain status in database"""
    # Implementation details...

async def run_test():
    """Run complete test flow"""
    print("DOMAIN PROCESSING TEST")
    print("======================")

    # Step 1: Find/reset domain
    domain_id = await find_and_reset_domain("example.com")
    if not domain_id:
        print("Failed to find/reset domain. Test aborted.")
        return

    # Step 2: Verify domain status
    await check_domain_status(domain_id)

    # Step 3: Process the domain
    try:
        print("Processing domain...")
        await process_pending_domains(limit=1)
        print("Domain processing triggered")
    except Exception as e:
        print(f"Error during domain processing: {str(e)}")

    # Step 4: Check results
    await asyncio.sleep(3)  # Wait for processing
    await check_domain_status(domain_id)

    print("Test complete!")

if __name__ == "__main__":
    asyncio.run(run_test())
```
