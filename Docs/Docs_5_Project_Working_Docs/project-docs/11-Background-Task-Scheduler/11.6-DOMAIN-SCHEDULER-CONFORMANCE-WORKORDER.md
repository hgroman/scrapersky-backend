# Domain Scheduler Database Conformance Work Order

## Urgency: HIGH

This work order addresses critical non-conformities in the `domain_scheduler.py` file regarding our mandated database interaction patterns. These issues must be fixed immediately to ensure proper database connection handling, transaction management, and error isolation.

## Context

The domain scheduler is a critical background service that processes domains in the "pending" state. After reviewing the code against our database interaction guidelines in `Docs/Docs_1_AI_GUIDES/07-DATABASE_CONNECTION_STANDARDS.md` and `Docs/Docs_1_AI_GUIDES/21-SCHEDULED_TASKS_APSCHEDULER_PATTERN.md`, we've identified several areas that do not fully comply with our standards.

## Issues to Fix

1. **Improper Operation Separation**

   - Issue: The metadata extraction and database update operations are in the same try/except block (lines 159-199)
   - Risk: If an error occurs during metadata extraction, the error handling for database operations might be bypassed
   - Standard: Each database operation should have its own session and error handling

2. **Incomplete Supavisor Options**

   - Issue: Missing the explicit `statement_cache_size=0` setting in session options (lines 79-91)
   - Risk: Potential prepared statement cache issues with Supavisor
   - Standard: All required Supavisor options must be explicitly set

3. **Hardcoded Diagnostic Directory**
   - Issue: The diagnostic directory is hardcoded to `/tmp/scraper_sky_scheduler_diagnostics`
   - Risk: Path might not be available or appropriate in all environments
   - Standard: Paths should be configurable via settings

## Required Changes

### 1. Refactor Metadata Extraction and Database Update

```python
# Step 2.2: Extract metadata - SEPARATE TRY/EXCEPT
try:
    # Process the domain using metadata extractor
    logger.debug(f"Standardizing domain: {url}")
    std_domain = standardize_domain(url)

    if not std_domain:
        raise ValueError(f"Invalid domain format: {url}")

    # Convert domain to proper URL for scraping
    domain_url = get_domain_url(std_domain)
    logger.debug(f"Converted domain to URL for scraping: {domain_url}")

    logger.debug(f"Extracting metadata for domain: {std_domain}")
    metadata = await detect_site_metadata(domain_url, max_retries=3)
    logger.debug(f"Metadata extraction complete for {std_domain}")

    if metadata is None:
        raise ValueError(f"Failed to extract metadata from {std_domain}")
except Exception as extraction_error:
    # Handle metadata extraction errors separately
    error_message = str(extraction_error)
    logger.error(f"Error extracting metadata for domain {domain_id}: {error_message}")
    logger.debug(traceback.format_exc())
    await handle_domain_error(domain_id, error_message)
    continue  # Skip to next domain

# Step 2.3: Update domain with results - SEPARATE TRY/EXCEPT
try:
    async with get_background_session() as result_session:
        async with result_session.begin():
            logger.debug(f"Updating domain {domain_id} with extracted metadata")

            # [Existing update code remains unchanged]
except Exception as db_error:
    # Handle database update errors
    error_message = str(db_error)
    logger.error(f"Error updating domain {domain_id} with metadata: {error_message}")
    logger.debug(traceback.format_exc())
    await handle_domain_error(domain_id, error_message)
```

### 2. Enhance Session Options with All Required Supavisor Settings

```python
try:
    # Set the supavisor options for this session
    logger.debug("Setting session options for Supavisor compatibility")

    # Required Supavisor parameters
    options = [
        ("SET statement_timeout = 90000", "90 seconds timeout"),
        ("SET idle_in_transaction_session_timeout = 120000", "120 seconds idle timeout"),
        ("SET statement_cache_size = 0", "Required for Supavisor compatibility")
    ]

    for sql, description in options:
        set_option = text(sql)
        set_option = set_option.execution_options(prepared=False)
        await fetch_session.execute(set_option)
        logger.debug(f"Set session option: {description}")
except Exception as e:
    logger.error(f"Error setting session options: {str(e)}")
    logger.debug(traceback.format_exc())
```

### 3. Use Configuration for Diagnostic Path

```python
# Import settings at the top of the file
from ..config.settings import Settings

# Create settings instance
settings = Settings()

# Use settings for diagnostic directory
DIAGNOSTIC_DIR = settings.get("DIAGNOSTIC_DIR", "/tmp/scraper_sky_scheduler_diagnostics")
os.makedirs(DIAGNOSTIC_DIR, exist_ok=True)
```

## Testing Requirements

1. **Isolation Test**

   - Verify that metadata extraction and database update operations are correctly isolated
   - Inject errors in the metadata extraction to confirm error handling works correctly
   - Confirm that database update uses a separate session

2. **Session Options Test**

   - Verify all required Supavisor options are correctly set
   - Check logs to confirm settings are applied

3. **End-to-End Test**
   - Test the scheduler with different domains in pending status
   - Verify correct state transitions (pending → processing → completed/error)
   - Check error handling for various failure scenarios

## Priority and Impact

- **Priority**: HIGH
- **Impact of Issue**: Potential database connection issues, improper error handling
- **Impact of Change**: Low-risk refactoring, no functional changes
- **Estimated Time**: 2-3 hours

## Acceptance Criteria

1. Code changes implemented exactly as specified
2. All tests pass successfully
3. No changes to functional behavior of the domain scheduler
4. Full compliance with database interaction standards
5. Proper logging of all operations

## Technical Notes

This work order focuses specifically on database interaction pattern compliance. It does not address functional improvements to the domain scheduler logic itself. The changes are designed to be minimal and focused on conforming to our established database standards.

## Related Documents

- Docs/Docs_1_AI_GUIDES/07-DATABASE_CONNECTION_STANDARDS.md
- Docs/Docs_1_AI_GUIDES/13-TRANSACTION_MANAGEMENT_GUIDE.md
- Docs/Docs_1_AI_GUIDES/21-SCHEDULED_TASKS_APSCHEDULER_PATTERN.md
- project-docs/11-Background-Task-Scheduler/11.4-domain_scheduler_changes_report.md
