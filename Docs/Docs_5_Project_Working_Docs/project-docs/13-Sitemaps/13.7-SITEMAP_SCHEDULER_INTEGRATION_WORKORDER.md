# Sitemap Scheduler Integration Work Order

**Document ID:** 13.7-SITEMAP-SCHEDULER-INTEGRATION-WORKORDER
**Date:** 2025-04-01
**Status:** Open
**Priority:** High
**Related Documents:** 13.6-SITEMAP_ARCHITECTURE, 13.5-SITEMAP_SYSTEM_OVERVIEW, 13.3-SITEMAP_SCHEDULER_WORKORDER

## 1. Executive Summary

This work order addresses the final integration of the sitemap scheduler service with the existing sitemap processing system. The scheduler component needs to be modified to detect pending jobs in the job table and trigger the existing sitemap processing functionality.

The implementation follows the producer-consumer architecture pattern where the scheduler acts as the consumer that detects work from a queue (job table) and triggers the processor (sitemap analyzer).

## 2. Current State

The sitemap processing system currently includes:

1. API endpoints for submitting domains for processing (`modernized_sitemap.py`)
2. Background task functionality for processing domains (`background_service.py`)
3. Storage mechanisms for sitemap data (`models/sitemap.py`)
4. A partially implemented scheduler (`sitemap_scheduler.py`)

The scheduler is currently stubbed out with placeholder processing logic and needs to be connected to the existing processing functionality.

## 3. Required Changes

### 3.1. Primary File to Modify

- **File:** `src/services/sitemap_scheduler.py`
- **Function:** `process_pending_sitemaps()`

### 3.2. Changes Required

1. Update the scheduler to query the job table for pending sitemap jobs
2. Extract domain information from job data
3. Call the existing `process_domain_with_own_session()` function for each job
4. Implement proper error handling
5. Ensure proper session management

### 3.3. Implementation Pattern

```python
# In src/services/sitemap_scheduler.py

# Add these imports
from ..services.sitemap.processing_service import process_domain_with_own_session
from ..services.job_service import job_service

async def process_pending_sitemaps(limit: int = 10):
    """Process pending sitemaps that have been queued for processing."""
    logger.info(f"Looking for up to {limit} pending sitemap jobs")

    # Get pending jobs from the job table
    pending_jobs = []
    try:
        async with get_background_session() as session:
            async with session.begin():
                # Query for pending jobs with type 'sitemap'
                pending_jobs = await job_service.get_pending_jobs(
                    session,
                    job_type="sitemap",
                    limit=limit
                )
                logger.info(f"Found {len(pending_jobs)} pending sitemap jobs")
    except Exception as e:
        logger.error(f"Error fetching pending jobs: {str(e)}")
        return

    # Process each job
    for job in pending_jobs:
        job_id = job.id
        # Get domain from job data
        try:
            job_data = job.result_data or {}
            domain = job_data.get("domain")
            if not domain:
                logger.error(f"Job {job_id} has no domain specified in job data")
                continue

            # Process the domain using existing function
            logger.info(f"Triggering processing for domain {domain} (job_id: {job_id})")
            await process_domain_with_own_session(
                job_id=job_id,
                domain=domain,
                user_id="scheduler",
                max_urls=1000
            )

        except Exception as e:
            logger.error(f"Error processing job {job_id}: {str(e)}")
            # Continue with next job - process_domain_with_own_session handles its own error statuses
            continue
```

## 4. Dependencies and Related Files

### 4.1. Direct Dependencies

- `src/services/sitemap/processing_service.py` - Contains `process_domain_with_own_session()`
- `src/services/job_service.py` - Provides job table operations
- `src/session/async_session.py` - Provides `get_background_session()`

### 4.2. Indirect Dependencies

- `src/services/sitemap/background_service.py` - Called by processing service
- `src/services/sitemap/analyzer_service.py` - Performs sitemap analysis
- `src/models/sitemap.py` - Database models for sitemaps
- `src/models/job.py` - Database model for jobs

## 5. Testing Requirements

### 5.1. Test Resources

Existing test scripts in `scripts/sitemap_scheduler/` will be used for testing:

- `add_test_sitemap.py` - Creates test sitemap entries
- `check_sitemap.py` - Verifies sitemap processing status
- `process_sitemap.py` - Manually triggers processing
- `monitor_scheduler.py` - Monitors scheduler operation

### 5.2. Test Approach

1. **Unit Testing:**

   - Test job query functionality
   - Test error handling
   - Test session management

2. **Integration Testing:**

   ```bash
   # Step 1: Add a test domain with pending status
   python scripts/sitemap_scheduler/add_test_sitemap.py --domain example.com

   # Step 2: Run the scheduler once
   python scripts/sitemap_scheduler/process_sitemap.py --trigger-scheduler

   # Step 3: Check status of the sitemap
   python scripts/sitemap_scheduler/check_sitemap.py --domain example.com

   # Expected: Status should transition from "pending" to "completed"
   ```

3. **End-to-End Testing:**

   ```bash
   # Step 1: Start the scheduler monitoring
   python scripts/sitemap_scheduler/monitor_scheduler.py --interval 30

   # Step 2: Add a test domain through the API
   curl -X POST "http://localhost:8000/api/v3/sitemap/scan" \
     -H "Content-Type: application/json" \
     -d '{"base_url": "example.com", "max_pages": 100}'

   # Step 3: Observe scheduler logs
   # Expected: Scheduler should detect and process the domain
   ```

## 6. Verification Criteria

A successful implementation must satisfy these requirements:

1. **Functional Requirements:**

   - Scheduler detects pending jobs in the job table
   - Scheduler correctly triggers processing for each job
   - Status updates are properly handled
   - Errors are properly logged and don't stop processing

2. **Non-Functional Requirements:**
   - Proper session management
   - Appropriate error handling
   - Comprehensive logging
   - Efficient resource usage

## 7. Implementation Checklist

- [ ] Update imports in `sitemap_scheduler.py`
- [ ] Implement job query functionality
- [ ] Connect to `process_domain_with_own_session()`
- [ ] Implement error handling
- [ ] Add logging
- [ ] Test with existing test scripts
- [ ] Update documentation

## 8. Risks and Mitigation

1. **Risk: Job table schema mismatch**

   - **Mitigation:** Verify job table schema before implementation
   - **Fallback:** Add schema validation to handle different formats

2. **Risk: Performance impact of too many concurrent jobs**

   - **Mitigation:** Use batch size limit
   - **Fallback:** Implement throttling if needed

3. **Risk: Error propagation**
   - **Mitigation:** Isolate each job processing with its own try/except
   - **Fallback:** Add circuit breaker pattern if needed

## 9. Timeline

1. Implementation: 1 day
2. Testing: 1 day
3. Documentation: 0.5 day
4. Total: 2.5 days

## 10. Reporting Requirements

Upon completion, create a detailed implementation report following the template in previous completion reports, documenting:

1. Changes made
2. Testing methodology
3. Test results
4. Any remaining issues
5. Lessons learned

This report should be saved as `13.8-SITEMAP-SCHEDULER-INTEGRATION-COMPLETION.md`
