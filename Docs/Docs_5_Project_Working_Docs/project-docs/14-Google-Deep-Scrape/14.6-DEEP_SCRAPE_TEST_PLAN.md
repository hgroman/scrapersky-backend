# 14.6 DEEP SCRAPE TEST PLAN (Curation-Driven Workflow)

**Document ID:** 14.6-DEEP_SCRAPE_TEST_PLAN
**Date:** 2023-04-03
**Status:** Planning
**Related Documents:**

- `14.1-GOOGLE MAPS DEEP SCRAPE IMPLEMENTATION PLAN.md` (Especially Section 4.6)
- `14.5-New-AI-Hand-Off.md`
- `scripts/testing/methodologies/incremental_testing_methodology.md`

## 1. Objective

To comprehensively test the Curation-Driven Google Maps Deep Scrape workflow, ensuring that places queued via the API are correctly processed by the background scheduler, resulting in accurate data persistence and status updates.

## 2. Scope

This plan covers testing for the following components involved in the Curation-Driven workflow:

- **Queueing API Endpoint:** `PUT /api/v3/places-staging/queue-deep-scan`
- **Modified Scheduler Logic:** The deep scan processing logic within `process_pending_jobs` in `src/services/sitemap_scheduler.py`.
- **Single Place Service:** `PlacesDeepService.process_single_deep_scan` (focusing on its interaction with the scheduler and status updates, core logic assumed tested in Phase 1).
- **Database State:** Changes in `places_staging` (status, error message) and `local_businesses` (data upsert).

## 2.1 Testing Environment & Conventions

This test plan assumes the following conventions and environment setup based on existing project patterns and documentation:

- **Test Runner:** Tests are executed using `pytest`.
- **Database Sessions:** Automated tests (Unit, Integration, E2E) **do not** rely on specialized database fixtures (`test_db_session`). Instead, they acquire database sessions directly within test functions using the standard application utility:

  ```python
  from src.session.async_session import get_session

  async with get_session() as session:
      # Perform database setup (seeding)
      # or verification (querying) here
      await session.execute(...)
  ```

  This pattern is consistent with examples found in `scripts/testing/test_batch_e2e.py` and `scripts/testing/test_page_scraper.py`. Tests are expected to manage their own transactions (e.g., using `async with session.begin():`) or rely on implicit commits/rollbacks as appropriate for the test scenario.

- **Test Data Isolation:** Tests requiring database interaction should ideally run against an isolated test database or use transaction management within the test function to ensure a clean state and avoid interfering with development data. Helper functions for seeding and cleaning up specific test data (like `seed_queued_place`, `cleanup_test_data` in the integration tests) are recommended.
- **Authentication:**
  - **API Tests (E2E):** API calls made using `httpx.AsyncClient` should be authenticated using the standard development token (`DEV_TOKEN`) available in the `.env` file, passed via the `Authorization: Bearer <token>` header.
  - **User/Tenant Context:** Tests needing user or tenant context can utilize the standard development IDs defined in configuration (e.g., `DEV_USER_ID`, `DEFAULT_TENANT_ID` - see `.env` and potentially `Docs/Docs_1_AI_GUIDES/10-TEST_USER_INFORMATION.md` for context).
- **External Services:** All external network calls, particularly to the Google Maps API (`googlemaps.Client.place`), **must be mocked** using `unittest.mock.patch` during integration and E2E tests to ensure test reliability, speed, and avoid actual API costs/calls.
- **Database Scripts (`scripts/db`):** Utility scripts located in `scripts/db` (e.g., `inspect_table.py`, `test_connection.py`) are intended for manual database inspection, setup, or debugging and are **not** part of the automated test execution flow.

## 3. Testing Strategy

We will follow an incremental testing approach, starting with focused unit tests, followed by integration tests verifying component interactions, and concluding with end-to-end tests validating the complete flow.

### 3.1 Unit Tests

- **Goal:** Isolate and verify the new scheduler logic added for deep scan processing.
- **Target:** The deep scan handling code block within `process_pending_jobs` in `src/services/sitemap_scheduler.py`.
- **Methodology:**
  - Use `pytest` framework with mocking (`unittest.mock` or similar).
  - Mock `get_background_session` and the session object itself.
  - Mock database query results (`session.execute`) to return controlled `Place` objects with `status == QueuedForDeepScan`.
  - Mock `PlacesDeepService` instance and its `process_single_deep_scan` method to simulate success and failure scenarios.
- **Verification Steps:**
  1.  Verify that the `select` statement query for `places_staging` with `QueuedForDeepScan` status is executed.
  2.  Verify that the `update` statement to set `status = ProcessingDeepScan` is executed correctly for each mocked item.
  3.  Verify that `PlacesDeepService.process_single_deep_scan` is called with the correct `place_id` (string) and `tenant_id` (string) arguments.
  4.  **Success Case:** When the mocked `process_single_deep_scan` returns successfully, verify the `update` statement to set `status = DeepScanComplete` is executed.
  5.  **Failure Case:** When the mocked `process_single_deep_scan` raises an exception, verify the `update` statement to set `status = DeepScanFailed` _and_ populate the `deep_scan_error` field is executed.
  6.  Verify error handling within the loop (e.g., one failure doesn't stop processing others).
  7.  Verify edge cases: No items found in queue, processing limit respected.

### 3.2 Integration Tests

- **Goal:** Verify the interaction between the scheduler logic and the single-place processing service, including database interactions.
- **Target:** Interaction between `sitemap_scheduler.process_pending_jobs` and `PlacesDeepService.process_single_deep_scan`, including `places_staging` and `local_businesses` tables.
- **Methodology:**
  - Use `pytest` with a test database (e.g., separate test DB or transactions with rollback).
  - Seed the test `places_staging` table with records having `status == QueuedForDeepScan` and known `place_id` / `tenant_id`.
  - **Crucially, mock the actual Google API call** made inside `PlacesDeepService.process_single_deep_scan` to return controlled success/failure/data responses without external network calls.
  - Invoke the `process_pending_jobs` function directly within the test.
- **Verification Steps:**
  1.  Check `places_staging` table: Verify status transitions correctly (`QueuedForDeepScan` -> `ProcessingDeepScan` -> `DeepScanComplete` or `DeepScanFailed`).
  2.  Check `places_staging` table: Verify `deep_scan_error` column is populated correctly on failure.
  3.  Check `local_businesses` table: Verify records corresponding to successfully processed `place_id`s are created or updated correctly based on the data returned by the _mocked_ Google API call.
  4.  Verify that failures in `process_single_deep_scan` (due to mocked API errors) result in the correct `Failed` status and do not incorrectly populate `local_businesses`.

### 3.3 End-to-End (E2E) Tests

- **Goal:** Validate the complete workflow from the API request to the final database state.
- **Target:** Full flow: API -> Scheduler Logic -> Service Logic -> Database Updates.
- **Methodology:**
  - Use `pytest` with a test database and `httpx.AsyncClient` for making API calls.
  - Seed `places_staging` with test records (status `New` or similar).
  - Use the test client to call `PUT /api/v3/places-staging/queue-deep-scan` with IDs corresponding to seeded records.
  - Verify the API response and check the database for the initial status update (`QueuedForDeepScan`).
  - Invoke the `process_pending_jobs` function directly (simulating scheduler).
  - **Ensure the actual Google API call within `process_single_deep_scan` is mocked** to control outcomes and avoid external calls.
  - Wait for processing to complete (may require async handling or simple sequential execution if invoking directly).
- **Verification Steps:**
  1.  Verify the final status (`DeepScanComplete` / `DeepScanFailed`) in the `places_staging` table for the queued items.
  2.  Verify the `deep_scan_error` field is populated correctly on simulated failures.
  3.  Verify the `local_businesses` table contains the correctly upserted data based on the _mocked_ Google API responses for successful items.
  4.  Verify no unexpected side effects occurred.

## 4. Execution Plan

1.  **Implement Unit Tests** for the scheduler logic changes.
    - **Status:** ✅ COMPLETED
    - **Location:** `tests/services/test_sitemap_scheduler.py`
2.  **Implement Integration Tests** for the scheduler-service interaction.
    - **Status:** ✅ COMPLETED
    - **Location:** `tests/integration/services/test_sitemap_scheduler_integration.py`
3.  **Implement E2E Tests** for the full API-to-DB flow.
    - **Status:** ✅ COMPLETED
    - **Location:** `tests/e2e/test_deep_scan_flow.py`
4.  **Run all tests** and ensure they pass.
    - **Status:** ⬜ PENDING
5.  **Address any failures** and iterate until all tests pass consistently.
    - **Status:** ⬜ PENDING
