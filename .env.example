# ScraperSky Backend Environment Variables
# Copy this file to .env and fill in your actual values.

# --- Supabase & Database Configuration ---
# Core Supabase connection details
SUPABASE_URL=your_supabase_url_here
SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here
SUPABASE_DB_PASSWORD=your_supabase_db_password_here
SUPABASE_JWT_SECRET=your_supabase_jwt_secret_here

# Supabase Pooler specific settings (if using Supavisor in pooler mode)
SUPABASE_POOLER_HOST=your_supabase_pooler_host_here
SUPABASE_POOLER_PORT=your_supabase_pooler_port_here # e.g., 6543
SUPABASE_POOLER_USER=your_supabase_pooler_user_here # e.g., supabase_pooler_USER
SUPABASE_POOLER_PASSWORD=your_supabase_pooler_password_here

# Direct Database connection settings (alternative or for direct connections if pooler not used for all services)
SUPABASE_DB_HOST=your_supabase_db_host_here
SUPABASE_DB_PORT=your_supabase_db_port_here # e.g., 5432
SUPABASE_DB_USER=your_supabase_db_user_here # e.g., postgres
SUPABASE_DB_NAME=postgres # Default Supabase DB name

# Full Database URL (can be used instead of individual components, Pydantic settings will prioritize this if set)
# Format: postgresql+asyncpg://USER:PASSWORD@HOST:PORT/DBNAME
DATABASE_URL=your_full_database_url_here # e.g., postgresql+asyncpg://user:pass@host:port/dbname

# Database connection pool settings (defaults are in settings.py, can be overridden)
DB_MIN_POOL_SIZE=1
DB_MAX_POOL_SIZE=10
DB_CONNECTION_TIMEOUT=60 # Increased from 30s in docker-compose for potentially long operations

# --- Application Settings ---
LOG_LEVEL=TRACE # As per docker-compose.yml, can be INFO, DEBUG, WARNING, ERROR, TRACE
PORT=8000
HOST=0.0.0.0
MAX_WORKERS=4 # Default for Uvicorn workers
ENVIRONMENT=development # Or 'production', 'staging'
CORS_ORIGINS="*" # Comma-separated list of allowed origins, or "*" for all. JSON array format also supported e.g. '["http://localhost:3000"]'
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36

# --- User & Tenant Settings ---
# These often have defaults in settings.py but can be overridden
DEVELOPMENT_USER_ID=your_valid_uuid_for_dev_user # Example: 123e4567-e89b-12d3-a456-426614174000
SYSTEM_USER_ID=00000000-0000-0000-0000-000000000000 # Standard system user UUID
DEFAULT_TENANT_ID=550e8400-e29b-41d4-a716-446655440000 # Standard default tenant UUID
DEV_USER_ID= # Optional: Specific UUID for a development user, may override DEVELOPMENT_USER_ID based on usage
DEV_TOKEN=scraper_sky_2024 # Internal/dev API calls token, overridden in docker-compose
SCRAPER_SKY_DEV_MODE=true # As per docker-compose.yml

# --- External API Keys ---
SCRAPER_API_KEY=your_scraper_api_key_here
GOOGLE_MAPS_API_KEY=your_google_maps_api_key_here

# --- ScraperAPI Cost Control Settings ---
# CRITICAL: These settings control expensive premium features to prevent credit waste
SCRAPER_API_ENABLE_PREMIUM=false          # Default: disabled (5-10x cost multiplier)
SCRAPER_API_ENABLE_JS_RENDERING=false     # Default: disabled (10-25x cost multiplier)
SCRAPER_API_ENABLE_GEOTARGETING=false     # Default: disabled (2-3x cost multiplier)
SCRAPER_API_MAX_RETRIES=1                 # Reduce from default 3 to minimize costs
SCRAPER_API_COST_CONTROL_MODE=true        # Enable cost monitoring and alerts
WF7_ENABLE_JS_RENDERING=false             # WF7 specific: disable JS by default

# --- Mautic Settings ---
MAUTIC_BASE_URL=your_mautic_base_url_here
MAUTIC_CLIENT_ID=your_mautic_client_id_here
MAUTIC_CLIENT_SECRET=your_mautic_client_secret_here

# --- GCP Settings ---
GCP_PROJECT_ID=your_gcp_project_id_here
GCP_SERVICE_ACCOUNT_EMAIL=your_gcp_service_account_email_here
GCP_SERVICE_ACCOUNT_PRIVATE_KEY="your_gcp_service_account_private_key_here_escaped_newlines"
GCP_SERVICE_ACCOUNT_TOKEN_URI=https://oauth2.googleapis.com/token

# --- Scheduler Settings ---
# Domain Scheduler (WF4)
DOMAIN_SCHEDULER_INTERVAL_MINUTES=1
DOMAIN_SCHEDULER_BATCH_SIZE=10
DOMAIN_SCHEDULER_MAX_INSTANCES=1

# Sitemap Scheduler (WF2, WF3, WF5)
SITEMAP_SCHEDULER_INTERVAL_MINUTES=1 # docker-compose.yml has 1, settings.py has 5. Align as needed.
SITEMAP_SCHEDULER_BATCH_SIZE=20 # docker-compose.yml has 20, settings.py has 5. Align as needed.
SITEMAP_SCHEDULER_MAX_INSTANCES=1

# Domain Sitemap Submission Scheduler (This was DOMAIN_SITEMAP_SCHEDULER in settings.py)
# Assuming this maps to what was in docker-compose as DOMAIN_SCHEDULER (verify if distinct functionality)
# If this is a *new* distinct scheduler, ensure its settings are unique from the general domain scheduler.
# For now, using values from settings.py for this specific scheduler:
DOMAIN_SITEMAP_SCHEDULER_INTERVAL_MINUTES=1
DOMAIN_SITEMAP_SCHEDULER_BATCH_SIZE=10
# DOMAIN_SITEMAP_SCHEDULER_MAX_INSTANCES=1 # Add if explicitly needed, defaults may apply in setup

# Sitemap Import Scheduler (WF6 - Renamed from Deep Scrape)
SITEMAP_IMPORT_SCHEDULER_INTERVAL_MINUTES=1
SITEMAP_IMPORT_SCHEDULER_BATCH_SIZE=20
SITEMAP_IMPORT_SCHEDULER_MAX_INSTANCES=1

# Page Curation Scheduler (WF7) - Variables identified as GAP
PAGE_CURATION_SCHEDULER_INTERVAL_MINUTES=1 # Example default
PAGE_CURATION_SCHEDULER_BATCH_SIZE=10 # Example default
PAGE_CURATION_SCHEDULER_MAX_INSTANCES=1 # Example default

# --- Path & Cache Settings ---
# BASE_DIR and STATIC_DIR are usually derived in settings.py, not set via .env
CACHE_TTL=3600 # Default cache TTL in seconds

# --- Diagnostic & Debug Settings ---
DIAGNOSTIC_DIR=/tmp/scraper_sky_scheduler_diagnostics
ENABLE_IMPORT_TRACING=true # As per docker-compose.yml, set to true to disable reload and enable import logging

# --- Storage Settings (from original .env.example) ---
# NEED_CLARITY: Is CHROMA_PERSIST_DIR actively used and should it be in Pydantic Settings (settings.py)?
# Or is it deprecated? Currently not in Pydantic Settings class.
CHROMA_PERSIST_DIR=./chroma_data
